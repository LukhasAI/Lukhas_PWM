"""
ðŸ§  Enhanced Brain Integration System
LUKHAS AI Multi-Brain Symphony Architecture

This module provides a complete brain integration system that combines:
- Multi-Brain Symphony orchestration
- Emotional memory integration  
- Voice modulation
- Dream processing
- Advanced memory systems

Replaces and enhances the previous brain_integration.py with superior architecture.
"""

import asyncio
import logging
import time
import math
import json
import uuid
import threading
from typing import Dict, List, Any, Optional, Union, Set, Tuple
from datetime import datetime
from enum import Enum
import os

# Configure logging
logger = logging.getLogger("Enhanced.BrainIntegration")
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Import MultiBrainSymphony components with fallback paths
try:
    from .MultiBrainSymphony import (
        MultiBrainSymphonyOrchestrator, 
        DreamsBrainSpecialist,
        MemoryBrainSpecialist, 
        LearningBrainSpecialist
    )
    SYMPHONY_AVAILABLE = True
except ImportError:
    try:
        from MultiBrainSymphony import (
            MultiBrainSymphonyOrchestrator, 
            DreamsBrainSpecialist,
            MemoryBrainSpecialist, 
            LearningBrainSpecialist
        )
        SYMPHONY_AVAILABLE = True
    except ImportError:
        logger.warning("MultiBrainSymphony components not available")
        SYMPHONY_AVAILABLE = False
        MultiBrainSymphonyOrchestrator = None

# Import core components with fallbacks
try:
    from orchestration.brain.spine.fold_engine import AGIMemory, MemoryFold, MemoryType, MemoryPriority
except ImportError:
    logger.warning("Core memory components not available - using fallbacks")
    AGIMemory = None

try:
    from DASHBOARD.Î›_as_agent.core.memory_folds import create_memory_fold, recall_memory_folds
    from DASHBOARD.as_agent.core.memory_folds import create_memory_fold, recall_memory_folds
except ImportError:
    logger.warning("Emotional memory folds not available")
    create_memory_fold = None
    recall_memory_folds = None

try:
    from VOICE.voice_integrator import VoiceIntegrator
except ImportError:
    VoiceIntegrator = None

try:
    from consciousness.core_consciousness.dream_engine.dream_reflection_loop import DreamReflectionLoop
except ImportError:
    DreamReflectionLoop = None


class EnhancedEmotionalProcessor:
    """Enhanced emotional processing with vector operations and voice integration"""
    
    def __init__(self):
        self.emotion_vectors = {
            "neutral": [0.0, 0.0, 0.0],
            "joy": [0.8, 0.9, 0.3],
            "sadness": [-0.8, -0.7, -0.2],
            "anger": [-0.8, 0.7, 0.3],
            "fear": [-0.7, 0.8, 0.0],
            "trust": [0.7, 0.5, 0.2],
            "surprise": [0.0, 0.9, 0.8],
            "anticipation": [0.6, 0.8, 0.0],
        }
        
        self.current_state = {
            "primary_emotion": "neutral",
            "intensity": 0.5,
            "secondary_emotions": {},
            "last_updated": datetime.now().isoformat(),
            "stability": 0.8,
        }
        
        self.emotional_history = []
        self.max_history = 50
        
    def update_emotional_state(self, primary_emotion: str, intensity: float = None, 
                             secondary_emotions: Dict[str, float] = None, 
                             metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Update emotional state with enhanced tracking"""
        
        # Store previous state
        self.emotional_history.append(self.current_state.copy())
        if len(self.emotional_history) > self.max_history:
            self.emotional_history = self.emotional_history[-self.max_history:]
        
        # Update state
        if primary_emotion in self.emotion_vectors:
            self.current_state["primary_emotion"] = primary_emotion
            
        if intensity is not None:
            self.current_state["intensity"] = max(0.0, min(1.0, intensity))
            
        if secondary_emotions:
            valid_secondary = {
                e: max(0.0, min(1.0, i))
                for e, i in secondary_emotions.items()
                if e in self.emotion_vectors
            }
            self.current_state["secondary_emotions"] = valid_secondary
            
        self.current_state["last_updated"] = datetime.now().isoformat()
        
        # Calculate stability based on emotional change
        if self.emotional_history:
            previous = self.emotional_history[-1]
            distance = self._calculate_emotion_distance(
                previous["primary_emotion"], 
                self.current_state["primary_emotion"]
            )
            self.current_state["stability"] = max(0.1, 1.0 - (distance / 2.0))
            
        return self.current_state
    
    def _calculate_emotion_distance(self, emotion1: str, emotion2: str) -> float:
        """Calculate distance between emotions in vector space"""
        if emotion1 not in self.emotion_vectors:
            emotion1 = "neutral"
        if emotion2 not in self.emotion_vectors:
            emotion2 = "neutral"
            
        vec1 = self.emotion_vectors[emotion1]
        vec2 = self.emotion_vectors[emotion2]
        
        # Simple Euclidean distance
        distance = sum((a - b) ** 2 for a, b in zip(vec1, vec2)) ** 0.5
        return distance
    
    def get_voice_modulation_params(self) -> Dict[str, Any]:
        """Generate voice modulation parameters based on emotional state"""
        emotion = self.current_state["primary_emotion"]
        intensity = self.current_state["intensity"]
        
        emotion_adjustments = {
            "joy": {"pitch": 0.3, "speed": 0.2, "energy": 0.4},
            "sadness": {"pitch": -0.3, "speed": -0.25, "energy": -0.3},
            "anger": {"pitch": 0.2, "speed": 0.3, "energy": 0.5},
            "fear": {"pitch": 0.4, "speed": 0.4, "energy": 0.2},
            "surprise": {"pitch": 0.5, "speed": 0.1, "energy": 0.4},
            "trust": {"pitch": -0.1, "speed": -0.1, "energy": 0.1},
            "anticipation": {"pitch": 0.2, "speed": 0.1, "energy": 0.3}
        }
        
        adjustments = emotion_adjustments.get(emotion, {"pitch": 0, "speed": 0, "energy": 0})
        
        return {
            "pitch_adjustment": adjustments["pitch"] * intensity,
            "speed_adjustment": adjustments["speed"] * intensity,
            "energy_adjustment": adjustments["energy"] * intensity,
            "emphasis_level": 0.5 + (intensity * 0.3),
            "pause_threshold": 0.3 + ((1.0 - self.current_state["stability"]) * 0.2)
        }


class EnhancedMemorySystem:
    """Enhanced memory system with emotional integration and dream consolidation"""
    
    def __init__(self, emotional_processor: EnhancedEmotionalProcessor, memory_path: str = "./enhanced_memory"):
        self.emotional_processor = emotional_processor
        self.memory_path = memory_path
        os.makedirs(memory_path, exist_ok=True)
        
        self.memory_store = {}
        self.emotional_associations = {}
        self.consolidation_queue = []
        
        # Statistics
        self.stats = {
            "total_memories": 0,
            "emotional_memories": 0,
            "consolidations": 0,
            "retrievals": 0
        }
        
    def store_memory_with_emotion(self, key: str, content: Any, emotion: str = None, 
                                tags: List[str] = None, priority: str = "medium",
                                metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Store memory with emotional context"""
        
        # Use current emotional state if none provided
        if emotion is None:
            emotion = self.emotional_processor.current_state["primary_emotion"]
            
        memory_entry = {
            "key": key,
            "content": content,
            "emotion": emotion,
            "tags": tags or [],
            "priority": priority,
            "metadata": metadata or {},
            "timestamp": datetime.now().isoformat(),
            "access_count": 0,
            "emotional_intensity": self.emotional_processor.current_state["intensity"]
        }
        
        # Store in memory
        self.memory_store[key] = memory_entry
        
        # Create emotional associations
        if emotion not in self.emotional_associations:
            self.emotional_associations[emotion] = []
        self.emotional_associations[emotion].append(key)
        
        # Update statistics
        self.stats["total_memories"] += 1
        if emotion != "neutral":
            self.stats["emotional_memories"] += 1
            
        # Add to consolidation queue if high priority
        if priority in ["high", "critical"]:
            self.consolidation_queue.append(key)
            
        logger.info(f"Stored memory '{key}' with emotion '{emotion}'")
        
        return {
            "status": "success",
            "key": key,
            "emotion": emotion,
            "memory_id": str(uuid.uuid4()),
            "timestamp": memory_entry["timestamp"]
        }
    
    def retrieve_with_emotional_context(self, key: str = None, target_emotion: str = None,
                                      similarity_threshold: float = 0.7) -> Dict[str, Any]:
        """Retrieve memories with emotional context"""
        
        self.stats["retrievals"] += 1
        
        if key and key in self.memory_store:
            # Direct retrieval
            memory = self.memory_store[key]
            memory["access_count"] += 1
            return {
                "status": "success",
                "memory": memory,
                "retrieval_type": "direct"
            }
            
        elif target_emotion:
            # Emotional retrieval
            similar_memories = []
            
            for emotion, keys in self.emotional_associations.items():
                distance = self.emotional_processor._calculate_emotion_distance(target_emotion, emotion)
                if distance <= (2.0 - similarity_threshold * 2.0):  # Convert threshold to distance
                    for memory_key in keys:
                        memory = self.memory_store[memory_key]
                        memory["emotional_distance"] = distance
                        similar_memories.append(memory)
                        
            # Sort by emotional similarity and recency
            similar_memories.sort(key=lambda m: (m.get("emotional_distance", 1.0), m["timestamp"]))
            
            return {
                "status": "success",
                "memories": similar_memories[:10],  # Return top 10
                "retrieval_type": "emotional_similarity",
                "target_emotion": target_emotion
            }
            
        else:
            return {
                "status": "error",
                "message": "Either key or target_emotion must be provided"
            }
    
    def dream_consolidate_memories(self, max_memories: int = 50) -> Dict[str, Any]:
        """Consolidate memories through dream-like processing"""
        
        if not self.consolidation_queue:
            return {"status": "no_memories_to_consolidate"}
            
        consolidated_memories = []
        
        # Process memories in consolidation queue
        for key in self.consolidation_queue[:max_memories]:
            if key in self.memory_store:
                memory = self.memory_store[key]
                
                # Dream-like processing: create associations and strengthen important memories
                consolidated_memory = {
                    "original_key": key,
                    "content": memory["content"],
                    "emotion": memory["emotion"],
                    "consolidation_strength": memory["emotional_intensity"] * memory["access_count"],
                    "dream_associations": self._generate_dream_associations(memory),
                    "consolidated_at": datetime.now().isoformat()
                }
                
                consolidated_memories.append(consolidated_memory)
                
        # Clear processed items from queue
        self.consolidation_queue = self.consolidation_queue[max_memories:]
        self.stats["consolidations"] += len(consolidated_memories)
        
        logger.info(f"Consolidated {len(consolidated_memories)} memories through dream processing")
        
        return {
            "status": "success",
            "consolidated_count": len(consolidated_memories),
            "remaining_queue": len(self.consolidation_queue),
            "consolidated_memories": consolidated_memories
        }
    
    def _generate_dream_associations(self, memory: Dict[str, Any]) -> List[str]:
        """Generate dream-like associations for memory consolidation"""
        associations = []
        
        # Find emotionally similar memories
        emotion = memory["emotion"]
        if emotion in self.emotional_associations:
            similar_keys = self.emotional_associations[emotion][:3]  # Top 3 similar
            associations.extend([f"emotional_link_{key}" for key in similar_keys])
        
        # Add content-based associations (simplified)
        content_str = str(memory["content"]).lower()
        if "creative" in content_str:
            associations.append("creativity_network")
        if "memory" in content_str:
            associations.append("meta_memory_network")
        if "learning" in content_str:
            associations.append("learning_network")
            
        return associations


class EnhancedBrainIntegration:
    """
    Enhanced Brain Integration System combining Multi-Brain Symphony with 
    emotional memory processing, voice modulation, and dream consolidation.
    
    This is the superior replacement for the previous brain_integration.py
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the Enhanced Brain Integration System"""
        
        self.config = config or {}
        logger.info("ðŸ§  Initializing Enhanced Brain Integration System")
        
        # Initialize core components
        self.emotional_processor = EnhancedEmotionalProcessor()
        self.memory_system = EnhancedMemorySystem(self.emotional_processor)
        
        # Initialize Multi-Brain Symphony if available
        if SYMPHONY_AVAILABLE:
            try:
                self.symphony_orchestrator = MultiBrainSymphonyOrchestrator(
                    emotional_oscillator=self.emotional_processor,
                    memory_integrator=self.memory_system
                )
                self.symphony_available = True
                logger.info("ðŸŽ¼ Multi-Brain Symphony orchestrator integrated")
            except Exception as e:
                logger.error(f"Failed to initialize symphony: {e}")
                self.symphony_orchestrator = None
                self.symphony_available = False
        else:
            self.symphony_orchestrator = None
            self.symphony_available = False
            
        # Initialize voice integration if available
        try:
            if VoiceIntegrator:
                self.voice_integrator = VoiceIntegrator()
            else:
                self.voice_integrator = None
        except Exception as e:
            logger.warning(f"Voice integrator not available: {e}")
            self.voice_integrator = None
            
        # Initialize dream engine if available
        try:
            if DreamReflectionLoop:
                self.dream_engine = DreamReflectionLoop()
            else:
                self.dream_engine = None
        except Exception as e:
            logger.warning(f"Dream engine not available: {e}")
            self.dream_engine = None
            
        # Background processing
        self.consolidation_running = False
        self.consolidation_thread = None
        
        # Processing statistics
        self.stats = {
            "symphony_processes": 0,
            "emotional_updates": 0,
            "memory_operations": 0,
            "voice_outputs": 0,
            "dream_consolidations": 0
        }
        
        logger.info("âœ… Enhanced Brain Integration System initialized successfully")
    
    async def process_with_symphony(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process input through Multi-Brain Symphony if available, fallback to standard processing"""
        
        if self.symphony_available and self.symphony_orchestrator:
            try:
                # Initialize symphony if not already done
                if not self.symphony_orchestrator.symphony_active:
                    await self.symphony_orchestrator.initialize_symphony()
                
                # Conduct symphony processing
                symphony_result = await self.symphony_orchestrator.conduct_symphony(input_data)
                
                # Integrate results with brain systems
                integrated_result = await self._integrate_symphony_results(symphony_result, input_data)
                
                self.stats["symphony_processes"] += 1
                
                return {
                    "status": "success",
                    "processing_type": "symphony_enhanced",
                    "symphony_result": symphony_result,
                    "integrated_result": integrated_result,
                    "coordination_quality": symphony_result.get("coordination_quality", 0.0)
                }
                
            except Exception as e:
                logger.error(f"Symphony processing failed, falling back to standard: {e}")
                return await self._standard_processing(input_data)
        else:
            return await self._standard_processing(input_data)
    
    async def _integrate_symphony_results(self, symphony_result: Dict[str, Any], 
                                        original_input: Dict[str, Any]) -> Dict[str, Any]:
        """Integrate symphony results with brain subsystems"""
        
        integrated = {
            "emotional_processing": {},
            "memory_integration": {},
            "voice_modulation": {},
            "dream_insights": [],
            "learning_adaptations": []
        }
        
        # Process emotional context from symphony
        emotional_context = symphony_result.get("emotional_context", {})
        if emotional_context and "primary_emotion" in emotional_context:
            self.emotional_processor.update_emotional_state(
                primary_emotion=emotional_context["primary_emotion"],
                intensity=emotional_context.get("intensity", 0.5),
                metadata={"source": "symphony_processing"}
            )
            integrated["emotional_processing"] = self.emotional_processor.current_state
            self.stats["emotional_updates"] += 1
        
        # Process specialized brain outputs
        specialized_processing = symphony_result.get("specialized_processing", {})
        
        # Memory brain integration
        if "memory" in specialized_processing:
            memory_result = specialized_processing["memory"]
            if memory_result.get("status") != "failed":
                # Store symphony insights as memories
                insights = symphony_result.get("synthesized_insights", [])
                for i, insight in enumerate(insights):
                    memory_key = f"symphony_insight_{int(time.time())}_{i}"
                    self.memory_system.store_memory_with_emotion(
                        key=memory_key,
                        content=insight,
                        emotion=emotional_context.get("primary_emotion", "neutral"),
                        tags=["symphony", "insight"],
                        priority="medium"
                    )
                integrated["memory_integration"] = memory_result
                self.stats["memory_operations"] += 1
        
        # Dreams brain integration  
        if "dreams" in specialized_processing:
            dreams_result = specialized_processing["dreams"]
            if dreams_result.get("status") != "failed":
                integrated["dream_insights"] = dreams_result.get("creative_insights", [])
        
        # Learning brain integration
        if "learning" in specialized_processing:
            learning_result = specialized_processing["learning"]
            if learning_result.get("status") != "failed":
                integrated["learning_adaptations"] = learning_result.get("adaptation_recommendations", [])
        
        # Generate voice modulation parameters
        integrated["voice_modulation"] = self.emotional_processor.get_voice_modulation_params()
        
        return integrated
    
    async def _standard_processing(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Standard processing fallback when symphony is not available"""
        
        # Extract content
        content = input_data.get("content", str(input_data))
        
        # Emotional analysis (simplified)
        emotion = "neutral"
        intensity = 0.5
        
        # Simple emotion detection based on content
        content_lower = content.lower()
        if any(word in content_lower for word in ["happy", "joy", "great", "excellent"]):
            emotion = "joy"
            intensity = 0.7
        elif any(word in content_lower for word in ["sad", "disappointed", "bad"]):
            emotion = "sadness"  
            intensity = 0.6
        elif any(word in content_lower for word in ["angry", "frustrated", "annoyed"]):
            emotion = "anger"
            intensity = 0.8
        
        # Update emotional state
        self.emotional_processor.update_emotional_state(emotion, intensity)
        
        # Store as memory
        memory_key = f"standard_process_{int(time.time())}"
        memory_result = self.memory_system.store_memory_with_emotion(
            key=memory_key,
            content=content,
            emotion=emotion,
            tags=["standard_processing"]
        )
        
        self.stats["memory_operations"] += 1
        self.stats["emotional_updates"] += 1
        
        return {
            "status": "success",
            "processing_type": "standard",
            "emotional_state": self.emotional_processor.current_state,
            "memory_result": memory_result,
            "voice_modulation": self.emotional_processor.get_voice_modulation_params()
        }
    
    def speak_with_emotion(self, text: str, override_emotion: str = None) -> Dict[str, Any]:
        """Generate speech with emotional modulation"""
        
        # Use override emotion or current state
        if override_emotion:
            self.emotional_processor.update_emotional_state(override_emotion)
        
        voice_params = self.emotional_processor.get_voice_modulation_params()
        
        # If voice integrator available, use it
        if self.voice_integrator:
            try:
                voice_result = self.voice_integrator.speak_with_modulation(text, voice_params)
                self.stats["voice_outputs"] += 1
                return voice_result
            except Exception as e:
                logger.error(f"Voice integration failed: {e}")
        
        # Fallback response
        self.stats["voice_outputs"] += 1
        return {
            "status": "text_only",
            "text": text,
            "emotional_modulation": voice_params,
            "current_emotion": self.emotional_processor.current_state["primary_emotion"]
        }
    
    def start_dream_consolidation(self, interval_minutes: int = 60) -> bool:
        """Start background dream consolidation process"""
        
        if self.consolidation_running:
            return False
            
        self.consolidation_running = True
        
        def consolidation_loop():
            logger.info(f"ðŸŒ™ Starting dream consolidation loop (every {interval_minutes} minutes)")
            
            while self.consolidation_running:
                try:
                    result = self.memory_system.dream_consolidate_memories()
                    if result["status"] == "success":
                        self.stats["dream_consolidations"] += 1
                        logger.info(f"Dream consolidation: {result['consolidated_count']} memories processed")
                        
                except Exception as e:
                    logger.error(f"Dream consolidation error: {e}")
                
                # Sleep with interruption checking
                for _ in range(interval_minutes * 60):
                    if not self.consolidation_running:
                        break
                    time.sleep(1)
                    
        self.consolidation_thread = threading.Thread(target=consolidation_loop, daemon=True)
        self.consolidation_thread.start()
        
        return True
    
    def stop_dream_consolidation(self) -> bool:
        """Stop background dream consolidation"""
        if self.consolidation_running:
            self.consolidation_running = False
            return True
        return False
    
    def get_comprehensive_status(self) -> Dict[str, Any]:
        """Get comprehensive status of all brain systems"""
        
        status = {
            "system_active": True,
            "components": {
                "emotional_processor": True,
                "memory_system": True,
                "symphony_orchestrator": self.symphony_available,
                "voice_integrator": self.voice_integrator is not None,
                "dream_engine": self.dream_engine is not None
            },
            "current_emotional_state": self.emotional_processor.current_state,
            "memory_stats": self.memory_system.stats,
            "processing_stats": self.stats,
            "consolidation_active": self.consolidation_running,
            "timestamp": datetime.now().isoformat()
        }
        
        # Add symphony status if available
        if self.symphony_available and self.symphony_orchestrator:
            try:
                status["symphony_status"] = self.symphony_orchestrator.get_symphony_status()
            except Exception as e:
                status["symphony_status"] = {"error": str(e)}
        
        return status


# Factory function for easy integration
def create_enhanced_brain_integration(config: Dict[str, Any] = None) -> EnhancedBrainIntegration:
    """
    Factory function to create Enhanced Brain Integration system
    
    Args:
        config: Configuration dictionary
        
    Returns:
        EnhancedBrainIntegration instance
    """
    return EnhancedBrainIntegration(config)


# Demonstration
async def demo_enhanced_integration():
    """Demonstrate the Enhanced Brain Integration system"""
    
    print("ðŸ§  Enhanced Brain Integration Demo")
    
    # Create system
    brain = create_enhanced_brain_integration()
    
    # Test data
    test_inputs = [
        {"content": "I'm feeling creative and want to learn something new", "type": "creative_learning"},
        {"content": "This is a sad memory I want to remember", "type": "emotional_memory"},
        {"content": "I'm excited about this new discovery!", "type": "positive_discovery"}
    ]
    
    # Process each input
    for i, test_input in enumerate(test_inputs):
        print(f"\n--- Test {i+1}: {test_input['type']} ---")
        
        result = await brain.process_with_symphony(test_input)
        print(f"Processing: {result['processing_type']}")
        
        if result['processing_type'] == 'symphony_enhanced':
            print(f"Coordination Quality: {result['coordination_quality']:.2f}")
            print(f"Insights: {len(result['symphony_result'].get('synthesized_insights', []))}")
        
        # Test speech
        speech_result = brain.speak_with_emotion(test_input["content"])
        print(f"Speech emotion: {speech_result.get('current_emotion', 'unknown')}")
    
    # Show final status
    status = brain.get_comprehensive_status()
    print(f"\nðŸŽ¼ Final Status:")
    print(f"Symphony available: {status['components']['symphony_orchestrator']}")
    print(f"Total memories: {status['memory_stats']['total_memories']}")
    print(f"Emotional memories: {status['memory_stats']['emotional_memories']}")
    print(f"Symphony processes: {status['processing_stats']['symphony_processes']}")


if __name__ == "__main__":
    asyncio.run(demo_enhanced_integration())
