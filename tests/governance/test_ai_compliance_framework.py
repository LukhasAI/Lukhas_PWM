"""
Test Suite for AI Regulatory Compliance Framework
================================================

Comprehensive tests for all compliance components including:
- EU AI Act compliance validation
- GDPR data protection validation  
- NIST AI Risk Management Framework
- Global compliance orchestration
"""

import asyncio
import unittest
from datetime import datetime
import sys
import os

# Add compliance framework to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from compliance.ai_regulatory_framework.eu_ai_act.compliance_validator import (
    EUAIActValidator, AISystemProfile, ComplianceAssessment, AISystemRiskCategory
)
from compliance.ai_regulatory_framework.gdpr.data_protection_validator import (
    GDPRValidator, DataProcessingActivity, LawfulBasis, DataCategory, ProcessingPurpose
)
from compliance.ai_regulatory_framework.nist.ai_risk_management import (
    NISTAIRiskManager, AISystemMetrics, AILifecycleStage, RiskLevel
)
from compliance.ai_regulatory_framework.global_compliance.multi_jurisdiction_engine import (
    GlobalComplianceEngine, GlobalComplianceProfile, Jurisdiction, ComplianceFramework
)

class TestAIComplianceFramework(unittest.TestCase):
    """Test cases for AI Regulatory Compliance Framework"""
    
    def setUp(self):
        """Set up test fixtures"""
        self.eu_validator = EUAIActValidator()
        self.gdpr_validator = GDPRValidator()
        self.nist_manager = NISTAIRiskManager()
        self.global_engine = GlobalComplianceEngine()
    
    def test_eu_ai_act_validator_initialization(self):
        """Test EU AI Act validator initialization"""
        self.assertIsInstance(self.eu_validator, EUAIActValidator)
        self.assertTrue(hasattr(self.eu_validator, 'high_risk_use_cases'))
        self.assertTrue(hasattr(self.eu_validator, 'prohibited_practices'))
        self.assertTrue(len(self.eu_validator.high_risk_use_cases) > 0)
    
    async def test_eu_ai_act_compliance_assessment(self):
        """Test EU AI Act compliance assessment"""
        # Create test AI system profile
        system_profile = AISystemProfile(
            system_id="test_ai_system_001",
            name="Test AI System",
            description="Test system for compliance validation",
            intended_use="automated decision making",
            deployment_context=["employment_workers_management"],
            data_types=["personal_data", "biometric_data"],
            algorithms_used=["machine_learning", "neural_networks"],
            human_oversight_level="meaningful",
            automated_decision_making=True,
            affects_fundamental_rights=True
        )
        
        # Perform assessment
        assessment = await self.eu_validator.assess_system_compliance(system_profile)
        
        # Validate assessment results
        self.assertIsInstance(assessment, ComplianceAssessment)
        self.assertEqual(assessment.system_id, "test_ai_system_001")
        self.assertEqual(assessment.risk_category, AISystemRiskCategory.HIGH_RISK)
        self.assertTrue(len(assessment.requirements) > 0)
        self.assertTrue(isinstance(assessment.confidence_score, float))
        self.assertTrue(0.0 <= assessment.confidence_score <= 1.0)
    
    async def test_gdpr_compliance_assessment(self):
        """Test GDPR compliance assessment"""
        # Create test data processing activity
        activity = DataProcessingActivity(
            activity_id="test_processing_001",
            name="Test Data Processing",
            description="Test processing activity",
            controller="Test Company",
            processor=None,
            data_categories=[DataCategory.PERSONAL_DATA, DataCategory.BIOMETRIC_DATA],
            lawful_basis=LawfulBasis.CONSENT,
            purposes=[ProcessingPurpose.SERVICE_PROVISION],
            data_subjects=["employees", "customers"],
            retention_period="2 years",
            international_transfers=True,
            automated_decision_making=True,
            profiling=True
        )
        
        # Perform assessment
        assessment = await self.gdpr_validator.assess_gdpr_compliance(activity)
        
        # Validate assessment results
        self.assertEqual(assessment.activity_id, "test_processing_001")
        self.assertTrue(isinstance(assessment.overall_score, float))
        self.assertTrue(0.0 <= assessment.overall_score <= 1.0)
        self.assertTrue(len(assessment.violations) >= 0)
        self.assertTrue(len(assessment.recommendations) > 0)
    
    async def test_nist_risk_assessment(self):
        """Test NIST AI Risk Management assessment"""
        # Create test AI system metrics
        metrics = AISystemMetrics(
            system_id="test_ai_system_001",
            accuracy=0.85,
            precision=0.82,
            recall=0.78,
            fairness_metrics={"demographic_parity": 0.75, "equalized_odds": 0.80},
            explainability_score=0.70,
            robustness_score=0.85,
            privacy_preservation_score=0.80,
            security_score=0.85
        )
        
        # Perform risk assessment
        assessment = await self.nist_manager.conduct_risk_assessment(
            "test_ai_system_001", metrics, AILifecycleStage.OPERATE_MONITOR
        )
        
        # Validate assessment results
        self.assertEqual(assessment.system_id, "test_ai_system_001")
        self.assertIn(assessment.risk_level, [RiskLevel.LOW, RiskLevel.MEDIUM, RiskLevel.HIGH, RiskLevel.CRITICAL])
        self.assertTrue(len(assessment.trustworthy_scores) > 0)
        self.assertTrue(len(assessment.mitigation_strategies) > 0)
    
    async def test_global_compliance_assessment(self):
        """Test global compliance orchestration"""
        # Create test global compliance profile
        profile = GlobalComplianceProfile(
            system_id="test_global_system_001",
            name="Global Test System",
            jurisdictions=[Jurisdiction.EU, Jurisdiction.US],
            frameworks=[ComplianceFramework.EU_AI_ACT, ComplianceFramework.GDPR, ComplianceFramework.NIST_AI_RMF],
            deployment_regions=["EU", "US"],
            data_residency_requirements={"EU": "EEA_only", "US": "US_only"},
            cross_border_transfers=True,
            regulatory_notifications=["EU_DPA", "US_FTC"]
        )
        
        # Create supporting data for assessments
        system_profile = AISystemProfile(
            system_id="test_global_system_001",
            name="Global Test System",
            description="Test system for global compliance",
            intended_use="automated decision making",
            deployment_context=["employment_workers_management"],
            data_types=["personal_data"],
            algorithms_used=["machine_learning"],
            human_oversight_level="meaningful",
            automated_decision_making=True,
            affects_fundamental_rights=True
        )
        
        activity = DataProcessingActivity(
            activity_id="test_global_system_001",
            name="Global Test Processing",
            description="Test processing for global system",
            controller="Global Test Company",
            processor=None,
            data_categories=[DataCategory.PERSONAL_DATA],
            lawful_basis=LawfulBasis.CONSENT,
            purposes=[ProcessingPurpose.SERVICE_PROVISION],
            data_subjects=["users"],
            retention_period="1 year",
            international_transfers=True,
            automated_decision_making=True,
            profiling=False
        )
        
        metrics = AISystemMetrics(
            system_id="test_global_system_001",
            accuracy=0.90,
            precision=0.88,
            recall=0.85,
            fairness_metrics={"demographic_parity": 0.85},
            explainability_score=0.80,
            robustness_score=0.90,
            privacy_preservation_score=0.85,
            security_score=0.90
        )
        
        # Perform global assessment
        report = await self.global_engine.assess_global_compliance(
            profile, system_profile, activity, metrics
        )
        
        # Validate global assessment results
        self.assertEqual(report.system_id, "test_global_system_001")
        self.assertIn(report.overall_status, ["Fully Compliant", "Mostly Compliant", "Partially Compliant", "Non-Compliant"])
        self.assertTrue(len(report.jurisdiction_compliance) > 0)
        self.assertTrue(len(report.framework_compliance) > 0)
    
    async def test_compliance_report_generation(self):
        """Test compliance report generation"""
        # Create minimal test data
        system_profile = AISystemProfile(
            system_id="test_report_001",
            name="Test Report System",
            description="Test system for report generation",
            intended_use="classification",
            deployment_context=["minimal_risk"],
            data_types=["public_data"],
            algorithms_used=["basic_ml"],
            human_oversight_level="effective",
            automated_decision_making=False,
            affects_fundamental_rights=False
        )
        
        # Perform assessment
        assessment = await self.eu_validator.assess_system_compliance(system_profile)
        
        # Generate report
        report = await self.eu_validator.generate_compliance_report(assessment)
        
        # Validate report structure
        self.assertIn("assessment_summary", report)
        self.assertIn("requirements", report)
        self.assertIn("violations", report)
        self.assertIn("recommendations", report)
        self.assertIn("next_steps", report)
        self.assertIn("regulatory_references", report)
    
    def test_framework_compatibility(self):
        """Test framework compatibility matrix"""
        compatibility = self.global_engine.framework_compatibility
        
        # Validate compatibility structure
        self.assertIn(ComplianceFramework.EU_AI_ACT, compatibility)
        self.assertIn(ComplianceFramework.GDPR, compatibility)
        
        # Validate compatibility scores
        eu_ai_act_compat = compatibility[ComplianceFramework.EU_AI_ACT]
        self.assertTrue(all(0.0 <= score <= 1.0 for score in eu_ai_act_compat.values()))
    
    async def test_error_handling(self):
        """Test error handling in compliance framework"""
        # Test with invalid system profile
        invalid_profile = AISystemProfile(
            system_id="",  # Invalid empty ID
            name="",
            description="",
            intended_use="",
            deployment_context=[],
            data_types=[],
            algorithms_used=[],
            human_oversight_level="",
            automated_decision_making=False,
            affects_fundamental_rights=False
        )
        
        try:
            assessment = await self.eu_validator.assess_system_compliance(invalid_profile)
            # Should still work but may have violations
            self.assertIsInstance(assessment, ComplianceAssessment)
        except Exception as e:
            # Error handling should be graceful
            self.assertIsInstance(e, Exception)
    
    def run_async_test(self, coro):
        """Helper to run async tests"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(coro)
        finally:
            loop.close()

def run_compliance_tests():
    """Run all compliance framework tests"""
    print("🧪 Running AI Regulatory Compliance Framework Tests...")
    
    # Create test suite
    suite = unittest.TestSuite()
    test_case = TestAIComplianceFramework()
    
    # Add sync tests
    suite.addTest(TestAIComplianceFramework('test_eu_ai_act_validator_initialization'))
    suite.addTest(TestAIComplianceFramework('test_framework_compatibility'))
    
    # Run sync tests
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # Run async tests manually
    print("\n🔄 Running async compliance tests...")
    
    async_tests = [
        'test_eu_ai_act_compliance_assessment',
        'test_gdpr_compliance_assessment', 
        'test_nist_risk_assessment',
        'test_global_compliance_assessment',
        'test_compliance_report_generation',
        'test_error_handling'
    ]
    
    async_results = []
    for test_name in async_tests:
        try:
            print(f"  ⚡ Running {test_name}...")
            test_method = getattr(test_case, test_name)
            test_case.run_async_test(test_method())
            print(f"  ✅ {test_name} passed")
            async_results.append(True)
        except Exception as e:
            print(f"  ❌ {test_name} failed: {e}")
            async_results.append(False)
    
    # Summary
    total_tests = len(suite._tests) + len(async_tests)
    passed_tests = result.testsRun - len(result.failures) - len(result.errors) + sum(async_results)
    
    print(f"\n📊 Test Results Summary:")
    print(f"  Total Tests: {total_tests}")
    print(f"  Passed: {passed_tests}")
    print(f"  Failed: {total_tests - passed_tests}")
    
    if passed_tests == total_tests:
        print("🎉 All compliance framework tests passed!")
        return True
    else:
        print("❌ Some compliance framework tests failed")
        return False

if __name__ == "__main__":
    success = run_compliance_tests()
    sys.exit(0 if success else 1)
