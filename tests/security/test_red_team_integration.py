"""
Red Team Framework Integration Tests
===================================

Comprehensive integration tests for the entire Red Team security framework.
Tests all components working together to validate AI system security.
"""

import asyncio
import sys
import os
from datetime import datetime

# Add parent directories to path for imports
sys.path.append('/Users/agi_dev/Lukhas_PWM')

def test_red_team_framework_integration():
    """Test complete Red Team framework integration"""
    
    print("üî¥ RED TEAM FRAMEWORK INTEGRATION TEST")
    print("=" * 60)
    
    # Test 1: Adversarial Testing Suite
    print("\n1Ô∏è‚É£ Testing Adversarial Testing Suite...")
    try:
        from security.red_team_framework.adversarial_testing import (
            AdversarialTestingSuite, AISystemTarget
        )
        
        # Create test target
        target = AISystemTarget(
            system_id="test_ai_system",
            name="Test AI System",
            model_type="language_model",
            endpoints=["http://localhost:8000/predict"],
            authentication_required=True
        )
        
        # Initialize adversarial testing suite
        adversarial_suite = AdversarialTestingSuite()
        
        print("   ‚úÖ Adversarial Testing Suite imported successfully")
        print(f"   üìä Target system: {target.name}")
        
    except ImportError as e:
        print(f"   ‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False
    
    # Test 2: Attack Simulation Engine
    print("\n2Ô∏è‚É£ Testing Attack Simulation Engine...")
    try:
        from security.red_team_framework.attack_simulation.attack_scenario_generator import (
            AIThreatModelingEngine, AttackSimulationEngine, ThreatActor
        )
        
        # Initialize threat modeling engine
        threat_engine = AIThreatModelingEngine()
        simulation_engine = AttackSimulationEngine()
        
        print("   ‚úÖ Attack Simulation Engine imported successfully")
        print(f"   üé≠ Available threat actors: {len(list(ThreatActor))}")
        
    except ImportError as e:
        print(f"   ‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False
    
    # Test 3: Security Control Validation
    print("\n3Ô∏è‚É£ Testing Security Control Validation...")
    try:
        from security.red_team_framework.validation_frameworks.security_control_validation import (
            SecurityControlRegistry, ControlValidationEngine, ControlCategory
        )
        
        # Initialize control validation
        control_registry = SecurityControlRegistry()
        validation_engine = ControlValidationEngine()
        
        # Test control retrieval
        all_controls = control_registry.get_all_controls()
        critical_controls = control_registry.get_critical_controls()
        
        print("   ‚úÖ Security Control Validation imported successfully")
        print(f"   üõ°Ô∏è Total controls: {len(all_controls)}")
        print(f"   üö® Critical controls: {len(critical_controls)}")
        
    except ImportError as e:
        print(f"   ‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False
    
    # Test 4: Penetration Testing Framework
    print("\n4Ô∏è‚É£ Testing Penetration Testing Framework...")
    try:
        from security.red_team_framework.penetration_testing.ai_penetration_tester import (
            AIPenetrationTester, PentestTarget, AttackVector
        )
        
        # Create penetration test target
        pentest_target = PentestTarget(
            target_id="test_target_001",
            name="Test AI API",
            description="Test AI system for penetration testing",
            target_type="api",
            endpoints=["http://localhost:8000"],
            authentication_required=True,
            scope=["model_inference", "api_security"]
        )
        
        # Initialize penetration tester
        pentest_engine = AIPenetrationTester()
        
        print("   ‚úÖ Penetration Testing Framework imported successfully")
        print(f"   üéØ Test target: {pentest_target.name}")
        print(f"   ‚öîÔ∏è Available attack vectors: {len(list(AttackVector))}")
        
    except ImportError as e:
        print(f"   ‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return False
    
    print("\n" + "=" * 60)
    print("üéâ ALL RED TEAM FRAMEWORK COMPONENTS IMPORTED SUCCESSFULLY!")
    return True

async def test_red_team_workflow():
    """Test complete Red Team workflow"""
    
    print("\nüîÑ RED TEAM WORKFLOW INTEGRATION TEST")
    print("=" * 60)
    
    try:
        # Import all components
        from security.red_team_framework.adversarial_testing import (
            AdversarialTestingSuite, AISystemTarget
        )
        from security.red_team_framework.attack_simulation.attack_scenario_generator import (
            AIThreatModelingEngine, AttackSimulationEngine, ThreatActor
        )
        from security.red_team_framework.validation_frameworks.security_control_validation import (
            SecurityControlRegistry, ControlValidationEngine
        )
        from security.red_team_framework.penetration_testing.ai_penetration_tester import (
            AIPenetrationTester, PentestTarget, AttackVector
        )
        
        # 1. Create test target
        print("\n1Ô∏è‚É£ Creating AI system target...")
        target = AISystemTarget(
            system_id="demo_ai_system",
            name="Demo AI System",
            model_type="language_model",
            endpoints=["http://localhost:8000/predict", "http://localhost:8000/train"],
            authentication_required=True
        )
        print(f"   ‚úÖ Created target: {target.name}")
        
        # 2. Generate threat scenarios
        print("\n2Ô∏è‚É£ Generating threat scenarios...")
        threat_engine = AIThreatModelingEngine()
        scenarios = await threat_engine.generate_threat_scenarios(
            target_system="demo_ai_system",
            threat_actors=[ThreatActor.CYBERCRIMINAL, ThreatActor.NATION_STATE]
        )
        print(f"   ‚úÖ Generated {len(scenarios)} threat scenarios")
        
        # 3. Run attack simulations
        print("\n3Ô∏è‚É£ Running attack simulations...")
        simulation_engine = AttackSimulationEngine()
        simulation_results = []
        
        for scenario in scenarios[:2]:  # Test first 2 scenarios
            result = await simulation_engine.execute_attack_simulation(scenario)
            simulation_results.append(result)
            print(f"   üìä Scenario: {scenario.name} - Success: {result.overall_success}")
        
        # 4. Validate security controls
        print("\n4Ô∏è‚É£ Validating security controls...")
        validation_engine = ControlValidationEngine()
        critical_controls = validation_engine.control_registry.get_critical_controls()
        
        validation_results = {}
        for control in critical_controls[:3]:  # Test first 3 critical controls
            results = await validation_engine.validate_control(control.control_id)
            validation_results[control.control_id] = results
            avg_score = sum(r.effectiveness_score for r in results) / len(results) if results else 0
            print(f"   üõ°Ô∏è Control {control.control_id}: {avg_score:.1f}% effective")
        
        # 5. Execute penetration test
        print("\n5Ô∏è‚É£ Executing penetration test...")
        pentest_target = PentestTarget(
            target_id="demo_target",
            name="Demo AI System",
            description="Demo system for penetration testing",
            target_type="model",
            endpoints=["http://localhost:8000/predict"],
            authentication_required=True,
            scope=["model_inference", "input_validation"]
        )
        
        pentest_engine = AIPenetrationTester()
        pentest_results = await pentest_engine.conduct_penetration_test(
            pentest_target,
            attack_vectors=[AttackVector.PROMPT_INJECTION, AttackVector.MODEL_EXTRACTION]
        )
        print(f"   üéØ Penetration test completed - Found {len(pentest_results.vulnerabilities)} vulnerabilities")
        
        # 6. Generate comprehensive report
        print("\n6Ô∏è‚É£ Generating comprehensive security report...")
        
        # Simulation report
        simulation_report = await simulation_engine.generate_simulation_report(simulation_results)
        
        # Validation report 
        validation_report = await validation_engine.generate_validation_report(validation_results)
        
        # Penetration test report
        pentest_report = await pentest_engine.generate_pentest_report(pentest_results)
        
        # Combine into comprehensive report
        comprehensive_report = {
            "assessment_date": datetime.now().isoformat(),
            "target_system": target.name,
            "attack_simulation": {
                "total_scenarios": len(scenarios),
                "success_rate": simulation_report["simulation_summary"]["attack_success_rate"],
                "detection_rate": simulation_report["simulation_summary"]["average_detection_rate"]
            },
            "control_validation": {
                "overall_effectiveness": validation_report["executive_summary"]["overall_effectiveness_score"],
                "critical_controls_tested": len(validation_results)
            },
            "penetration_testing": {
                "vulnerabilities_found": len(pentest_results.vulnerabilities),
                "risk_level": pentest_results.risk_assessment["overall_risk"],
                "max_cvss_score": pentest_results.risk_assessment["risk_score"]
            },
            "overall_security_posture": "NEEDS_IMPROVEMENT",  # Based on findings
            "priority_actions": [
                "Address high-severity vulnerabilities immediately",
                "Strengthen AI-specific security controls", 
                "Implement continuous monitoring and detection",
                "Conduct regular red team exercises"
            ]
        }
        
        print(f"   üìã Comprehensive report generated")
        print(f"   üìä Overall security posture: {comprehensive_report['overall_security_posture']}")
        print(f"   üö® Priority actions: {len(comprehensive_report['priority_actions'])}")
        
        print("\n" + "=" * 60)
        print("üéâ RED TEAM WORKFLOW COMPLETED SUCCESSFULLY!")
        print(f"üìà Attack Success Rate: {simulation_report['simulation_summary']['attack_success_rate']:.1%}")
        print(f"üõ°Ô∏è Control Effectiveness: {validation_report['executive_summary']['overall_effectiveness_score']:.1f}%")
        print(f"üéØ Vulnerabilities Found: {len(pentest_results.vulnerabilities)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Workflow test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Run all Red Team framework tests"""
    
    print("üöÄ LUKHAS PWM RED TEAM FRAMEWORK - COMPREHENSIVE TESTING")
    print("=" * 80)
    
    # Test 1: Component imports
    import_success = test_red_team_framework_integration()
    
    if not import_success:
        print("‚ùå Component import tests failed. Stopping.")
        return False
    
    # Test 2: Workflow integration
    workflow_success = asyncio.run(test_red_team_workflow())
    
    if not workflow_success:
        print("‚ùå Workflow integration tests failed.")
        return False
    
    # Final summary
    print("\n" + "=" * 80)
    print("üéØ RED TEAM FRAMEWORK TESTING SUMMARY")
    print("=" * 80)
    print("‚úÖ Component Import Tests: PASSED")
    print("‚úÖ Workflow Integration Tests: PASSED") 
    print("‚úÖ Attack Simulation: FUNCTIONAL")
    print("‚úÖ Security Control Validation: FUNCTIONAL")
    print("‚úÖ Penetration Testing: FUNCTIONAL")
    print("‚úÖ Comprehensive Reporting: FUNCTIONAL")
    
    print("\nüî¥ RED TEAM FRAMEWORK IS FULLY OPERATIONAL!")
    print("Ready for AI system security testing and validation.")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
