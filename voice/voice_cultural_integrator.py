"""
Enhanced Core TypeScript - Integrated from Advanced Systems
Original: voice_cultural_integration.py
Advanced: voice_cultural_integration.py
Integration Date: 2025-05-31T07:55:28.254343
"""

"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ MODULE        : voice_cultural_integration.py                             â•‘
â•‘ DESCRIPTION   : Integrates the accent adapter module with the voice       â•‘
â•‘                 memory helix and emotion mapping systems to enable        â•‘
â•‘                 cultural curiosity, accent adaptation, and location       â•‘
â•‘                 memory features.                                          â•‘
â•‘ TYPE          : Integration Module           VERSION: v1.0.0              â•‘
â•‘ AUTHOR        : LUKHAS SYSTEMS                  CREATED: 2025-05-09        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DEPENDENCIES:
- accent_adapter.py
- voice_memory_helix.py
- emotion_mapper_alt.py
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from ..spine.accent_adapter import AccentAdapter
from ..spine.emotion_mapper_alt import LUKHAS

logger = logging.getLogger("voice_cultural_integration")

class VoiceCulturalIntegrator:
    """
    Integrates accent adaptation, emotion mapping, and voice memory systems
    to provide holistic cultural awareness capabilities.
    """

    def __init__(self, core_interface=None, config: Dict[str, Any] = None):
        """
        Initialize the voice cultural integrator.

        Args:
            core_interface: Interface to core system
            config: Configuration parameters
        """
        self.config = config or {}
        self.core = core_interface

        # Initialize components or get references to them
        self.emotion_mapper = self._get_emotion_mapper()
        self.memory_helix = self._get_memory_helix()
        self.accent_adapter = AccentAdapter(
            emotion_mapper=self.emotion_mapper,
            memory_helix=self.memory_helix,
            config=self.config.get("accent_adapter", {})
        )

        # Settings
        self.reminiscence_chance = self.config.get("reminiscence_chance", 0.2)
        self.cultural_learning_enabled = self.config.get("cultural_learning_enabled", True)

        logger.info("Voice Cultural Integrator initialized")

    def _get_emotion_mapper(self):
        """Get or create the emotion mapper."""
        if hasattr(self.core, "emotion_mapper"):
            return self.core.emotion_mapper

        # Create simple wrapper if we don't have direct reference
        class EmotionMapperWrapper:
            @property
            def emotions(self):
                return LUKHAS["emotions"]

            @property
            def baby_modes(self):
                return LUKHAS["baby_modes"]

        return EmotionMapperWrapper()

    def _get_memory_helix(self):
        """Get the memory helix from the core."""
        if hasattr(self.core, "memory_helix"):
            return self.core.memory_helix
        elif hasattr(self.core, "get_component"):
            try:
                return self.core.get_component("memory_helix")
            except:
                logger.warning("Could not get memory helix from core")
                return None
        return None

    async def process_cultural_context(self,
                                    user_text: str,
                                    user_id: str,
                                    context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process cultural context from user input and update the context.

        Args:
            user_text: Text from the user
            user_id: User identifier
            context: Existing context dictionary

        Returns:
            Updated context with cultural information
        """
        if not user_text:
            return context

        # Get user interaction history if available
        user_history = await self._get_user_history(user_id)

        # Detect cultural context
        cultural_context = self.accent_adapter.detect_cultural_context(user_text, user_history)
        context["cultural_context"] = cultural_context

        # Get appropriate voice mode
        voice_mode = self.accent_adapter.get_voice_mode_for_context(cultural_context)
        if voice_mode:
            context["voice_mode"] = voice_mode

        # Check for location mentions to build memory
        location = await self._extract_location(user_text, context)
        if location:
            context["detected_location"] = location

            # Record in accent adapter
            words_learned = []
            if self.memory_helix and hasattr(self.memory_helix, "detect_new_words"):
                try:
                    words_learned = await self.memory_helix.detect_new_words(user_text)
                except:
                    pass

            accent_detected = context.get("accent_info", {}).get("name") if context.get("accent_info") else None

            self.accent_adapter.remember_location(
                user_id=user_id,
                location=location,
                accent_detected=accent_detected,
                words_learned=words_learned
            )

        return context

    async def _extract_location(self, text: str, context: Dict[str, Any]) -> Optional[str]:
        """Extract location mentions from text."""
        # Simple extraction - in production, would use NER
        location_indicators = ["in ", "at ", "from ", "visiting ", "to "]

        # Check if location is already in context
        if context.get("location"):
            return context["location"]

        # Very simple location extraction
        for indicator in location_indicators:
            if indicator in text.lower():
                parts = text.lower().split(indicator)
                if len(parts) > 1:
                    location_phrase = parts[1].split()[0]
                    if len(location_phrase) > 3:  # Avoid tiny words
                        # Remove punctuation
                        import re
                        location = re.sub(r'[^\w\s]', '', location_phrase).strip()
                        if location:
                            return location

        return None

    async def _get_user_history(self, user_id: str) -> List[Dict[str, Any]]:
        """Get user interaction history if available."""
        if self.core and hasattr(self.core, "get_user_history"):
            try:
                return await self.core.get_user_history(user_id, limit=10)
            except:
                logger.warning(f"Failed to get user history for {user_id}")

        return []

    async def generate_cultural_response(self,
                                     base_response: str,
                                     user_id: str,
                                     context: Dict[str, Any]) -> str:
        """
        Enhance response with cultural awareness features like reminiscence.

        Args:
            base_response: Original response text
            user_id: User identifier
            context: Context with cultural information

        Returns:
            Enhanced response with cultural features
        """
        if not self.accent_adapter:
            return base_response

        updated_response = base_response

        # Generate reminiscence if appropriate
        should_reminisce = (
            # Random chance
            random.random() < self.reminiscence_chance and
            # Only if we have a location context
            ("detected_location" in context or
             "location" in context)
        )

        if should_reminisce:
            reminiscence = self.accent_adapter.generate_reminiscence(user_id, context)
            if reminiscence:
                # Add reminiscence as new paragraph
                updated_response = f"{updated_response}\n\n{reminiscence}"

        # Check if we should be curious about words
        cultural_context = context.get("cultural_context", "casual")

        # Extract unusual words (longer words are more likely to be interesting)
        words = [w for w in re.findall(r'\b[a-zA-Z\']+\b', context.get("user_text", "")) if len(w) > 5]

        for word in words:
            if self.accent_adapter.should_express_curiosity(word, cultural_context):
                curiosity_question = self.accent_adapter.generate_curiosity_question(
                    word, cultural_context)

                # Add curiosity question
                updated_response = f"{updated_response}\n\n{curiosity_question}"

                # Only ask about one word at a time to be respectful
                self.accent_adapter.log_cultural_interaction(
                    user_id=user_id,
                    word=word,
                    cultural_context=cultural_context
                )
                break

        return updated_response

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ” USAGE GUIDE (for voice_cultural_integration.py)
#
# 1. Initialize the integrator:
#       integrator = VoiceCulturalIntegrator(core_interface=core)
#
# 2. Process cultural context:
#       context = await integrator.process_cultural_context(user_text, user_id, context)
#
# 3. Generate culturally enhanced response:
#       enhanced_response = await integrator.generate_cultural_response(
#           base_response, user_id, context)
#
# END OF FILE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
