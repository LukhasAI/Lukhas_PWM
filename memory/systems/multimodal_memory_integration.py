"""
Multimodal Memory Integration Module
Provides integration wrapper for connecting the multimodal memory support to the memory hub
"""

import asyncio
import logging
from typing import Dict, Any, Optional, List, Tuple, Union
from datetime import datetime
import numpy as np
from pathlib import Path

from .multimodal_memory_support import (
    ModalityType,
    ModalityMetadata,
    MultiModalMemoryData,
    ImageProcessor,
    AudioProcessor,
    MultiModalMemoryProcessor,
    create_multimodal_memory
)

logger = logging.getLogger(__name__)


class MultimodalMemoryIntegration:
    """
    Integration wrapper for the Multimodal Memory Support System.
    Provides a simplified interface for the memory hub.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize the multimodal memory integration"""
        self.config = config or {
            'enable_cross_modal_alignment': True,
            'unified_embedding_dim': 1024,
            'modal_embedding_dim': 512,
            'max_memory_size_mb': 100,
            'enable_compression': True
        }

        # Initialize the multimodal memory processor
        self.processor = MultiModalMemoryProcessor(
            enable_cross_modal_alignment=self.config['enable_cross_modal_alignment'],
            unified_embedding_dim=self.config['unified_embedding_dim'],
            modal_embedding_dim=self.config['modal_embedding_dim']
        )

        # Initialize individual processors with custom settings
        self.image_processor = ImageProcessor(
            max_dimension=self.config.get('max_image_dimension', 512),
            quality=self.config.get('image_quality', 85),
            enable_feature_extraction=True
        )

        self.audio_processor = AudioProcessor(
            target_sample_rate=self.config.get('audio_sample_rate', 16000),
            max_duration_seconds=self.config.get('max_audio_duration', 30.0),
            enable_feature_extraction=True
        )

        self.is_initialized = False
        self.memory_cache = {}

        logger.info("MultimodalMemoryIntegration initialized with config: %s", self.config)

    async def initialize(self):
        """Initialize the multimodal memory system and its components"""
        if self.is_initialized:
            return

        try:
            logger.info("Initializing multimodal memory system components...")

            # Check available modality support
            await self._check_modality_support()

            # Initialize memory optimization
            await self._initialize_memory_optimization()

            # Load any pre-trained embeddings or models
            await self._load_embedding_models()

            self.is_initialized = True
            logger.info("Multimodal memory system initialization complete")

        except Exception as e:
            logger.error(f"Failed to initialize multimodal memory system: {e}")
            raise

    async def _check_modality_support(self):
        """Check which modalities are supported based on available libraries"""
        support_status = {
            "text": True,  # Always available
            "image": self._check_image_support(),
            "audio": self._check_audio_support(),
            "video": self._check_video_support()
        }

        logger.info("Modality support status: %s", support_status)
        self.supported_modalities = support_status

    def _check_image_support(self) -> bool:
        """Check if image processing is available"""
        try:
            from PIL import Image
            return True
        except ImportError:
            logger.warning("PIL not available - image processing disabled")
            return False

    def _check_audio_support(self) -> bool:
        """Check if audio processing is available"""
        try:
            import librosa
            import soundfile
            return True
        except ImportError:
            logger.warning("Audio libraries not available - audio processing disabled")
            return False

    def _check_video_support(self) -> bool:
        """Check if video processing is available"""
        try:
            import cv2
            return True
        except ImportError:
            logger.warning("OpenCV not available - video processing disabled")
            return False

    async def _initialize_memory_optimization(self):
        """Initialize memory optimization strategies"""
        # Set up compression policies
        self.compression_policies = {
            ModalityType.IMAGE: {'enabled': True, 'quality': 85},
            ModalityType.AUDIO: {'enabled': True, 'bitrate': 128},
            ModalityType.VIDEO: {'enabled': True, 'codec': 'h264'}
        }

    async def _load_embedding_models(self):
        """Load pre-trained embedding models if available"""
        # This would load actual models in production
        logger.info("Loading embedding models (placeholder)")

    async def create_memory(self,
                          text: Optional[str] = None,
                          image: Optional[Union[bytes, str, Path]] = None,
                          audio: Optional[Union[bytes, str, Path]] = None,
                          video: Optional[Union[bytes, str, Path]] = None,
                          tags: Optional[List[str]] = None,
                          metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create a multimodal memory from various inputs

        Args:
            text: Text content
            image: Image data (bytes) or path
            audio: Audio data (bytes) or path
            video: Video data (bytes) or path
            tags: Memory tags for categorization
            metadata: Additional metadata

        Returns:
            Dict containing memory ID and details
        """
        if not self.is_initialized:
            await self.initialize()

        # Convert file paths to bytes
        image_bytes = await self._load_file_if_path(image) if image else None
        audio_bytes = await self._load_file_if_path(audio) if audio else None
        video_bytes = await self._load_file_if_path(video) if video else None

        # Create the multimodal memory
        memory_item = await create_multimodal_memory(
            text_content=text,
            image_data=image_bytes,
            audio_data=audio_bytes,
            video_data=video_bytes,
            tags=tags or [],
            metadata=metadata or {}
        )

        # Store in cache
        memory_id = f"mm_{datetime.now().timestamp()}"
        self.memory_cache[memory_id] = memory_item

        return {
            'memory_id': memory_id,
            'modalities': self._get_present_modalities(text, image_bytes, audio_bytes, video_bytes),
            'tags': tags or [],
            'created_at': datetime.now().isoformat()
        }

    async def _load_file_if_path(self, data: Union[bytes, str, Path]) -> bytes:
        """Load file data if path is provided"""
        if isinstance(data, (str, Path)):
            path = Path(data)
            if path.exists():
                return path.read_bytes()
        return data

    def _get_present_modalities(self, text: Any, image: Any, audio: Any, video: Any) -> List[str]:
        """Get list of modalities present in the memory"""
        modalities = []
        if text: modalities.append("text")
        if image: modalities.append("image")
        if audio: modalities.append("audio")
        if video: modalities.append("video")
        return modalities

    async def process_multimodal_data(self, data: MultiModalMemoryData) -> Dict[str, Any]:
        """
        Process multimodal memory data

        Args:
            data: MultiModalMemoryData instance

        Returns:
            Processed memory with embeddings and metadata
        """
        if not self.is_initialized:
            await self.initialize()

        return await self.processor.process(data)

    async def retrieve_memory(self, memory_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve a memory by ID

        Args:
            memory_id: Memory identifier

        Returns:
            Memory data or None if not found
        """
        if memory_id in self.memory_cache:
            return self.memory_cache[memory_id]
        return None

    async def search_memories(self,
                            query: Union[str, bytes, np.ndarray],
                            modality: Optional[ModalityType] = None,
                            top_k: int = 10) -> List[Dict[str, Any]]:
        """
        Search memories using multimodal queries

        Args:
            query: Search query (text, image data, or embedding)
            modality: Specific modality to search in
            top_k: Number of results to return

        Returns:
            List of matching memories
        """
        if not self.is_initialized:
            await self.initialize()

        # This is a placeholder implementation
        # In production, this would use vector similarity search
        results = []

        # Simple text search for demonstration
        if isinstance(query, str) and modality in [None, ModalityType.TEXT]:
            for memory_id, memory in self.memory_cache.items():
                if hasattr(memory, 'text_content') and memory.text_content:
                    if query.lower() in memory.text_content.lower():
                        results.append({
                            'memory_id': memory_id,
                            'score': 0.8,  # Placeholder score
                            'preview': memory.text_content[:100]
                        })

        return results[:top_k]

    def get_supported_modalities(self) -> Dict[str, bool]:
        """Get supported modalities and their availability"""
        return self.supported_modalities

    def get_memory_statistics(self) -> Dict[str, Any]:
        """Get statistics about stored memories"""
        stats = {
            'total_memories': len(self.memory_cache),
            'modality_counts': defaultdict(int),
            'total_size_mb': 0.0
        }

        for memory in self.memory_cache.values():
            # Count modalities
            if hasattr(memory, 'modality_metadata'):
                for modality in memory.modality_metadata:
                    stats['modality_counts'][modality.value] += 1

        return dict(stats)

    async def optimize_memory_storage(self):
        """Optimize memory storage by compressing or removing old memories"""
        logger.info("Running memory optimization...")

        # This would implement actual optimization strategies
        # For now, just log the action
        before_size = len(self.memory_cache)

        # Remove memories older than threshold (placeholder)
        # In production, this would be more sophisticated

        after_size = len(self.memory_cache)
        logger.info(f"Memory optimization complete. Removed {before_size - after_size} memories")

    async def update_awareness(self, awareness_state: Dict[str, Any]):
        """
        Update multimodal memory system with current awareness state
        Called by memory hub during awareness broadcasts
        """
        logger.debug(f"Multimodal memory received awareness update: {awareness_state}")

        # Adjust memory processing based on awareness level
        if awareness_state.get("level") == "active":
            # More detailed processing during active awareness
            self.config['enable_cross_modal_alignment'] = True
            self.config['unified_embedding_dim'] = 1024
        elif awareness_state.get("level") == "passive":
            # Faster, less detailed processing during passive awareness
            self.config['enable_cross_modal_alignment'] = False
            self.config['unified_embedding_dim'] = 512


# Factory function for creating the integration
def create_multimodal_memory_integration(config: Optional[Dict[str, Any]] = None) -> MultimodalMemoryIntegration:
    """Create and return a multimodal memory integration instance"""
    return MultimodalMemoryIntegration(config)


# Import defaultdict if not already imported
from collections import defaultdict