"""
Security Control Validation Framework
====================================

Comprehensive security control testing and validation for AI systems:
- Control effectiveness testing
- Configuration validation  
- Compliance verification
- Performance benchmarking
- Gap analysis and remediation
"""

import asyncio
import logging
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Any, Optional, Tuple, Callable
from datetime import datetime
import json

logger = logging.getLogger(__name__)

class ControlCategory(Enum):
    """Security control categories"""
    ACCESS_CONTROL = "access_control"
    AUTHENTICATION = "authentication"
    AUTHORIZATION = "authorization"
    DATA_PROTECTION = "data_protection"
    MONITORING = "monitoring"
    INCIDENT_RESPONSE = "incident_response"
    VULNERABILITY_MANAGEMENT = "vulnerability_management"
    CONFIGURATION_MANAGEMENT = "configuration_management"
    AI_SPECIFIC = "ai_specific"

class ControlType(Enum):
    """Types of security controls"""
    PREVENTIVE = "preventive"
    DETECTIVE = "detective"
    CORRECTIVE = "corrective"
    COMPENSATING = "compensating"

class ValidationMethod(Enum):
    """Control validation methods"""
    AUTOMATED_SCAN = "automated_scan"
    MANUAL_REVIEW = "manual_review"
    PENETRATION_TEST = "penetration_test"
    CONFIGURATION_AUDIT = "configuration_audit"
    BEHAVIORAL_TEST = "behavioral_test"

class ControlStatus(Enum):
    """Control validation status"""
    EFFECTIVE = "effective"
    PARTIALLY_EFFECTIVE = "partially_effective"
    INEFFECTIVE = "ineffective"
    NOT_IMPLEMENTED = "not_implemented"
    MISCONFIGURED = "misconfigured"

@dataclass
class SecurityControl:
    """Individual security control definition"""
    control_id: str
    name: str
    description: str
    category: ControlCategory
    control_type: ControlType
    validation_methods: List[ValidationMethod]
    compliance_frameworks: List[str]
    criticality: str  # High, Medium, Low
    implementation_status: str
    
@dataclass
class ValidationTest:
    """Individual validation test"""
    test_id: str
    control_id: str
    test_name: str
    test_description: str
    validation_method: ValidationMethod
    test_procedure: str
    expected_outcome: str
    automated: bool

@dataclass
class ValidationResult:
    """Control validation result"""
    test_id: str
    control_id: str
    validation_date: datetime
    status: ControlStatus
    effectiveness_score: float  # 0-100
    findings: List[str]
    evidence: Dict[str, Any]
    recommendations: List[str]
    remediation_priority: str

class SecurityControlRegistry:
    """
    Registry of security controls for AI systems
    
    Maintains comprehensive catalog of security controls
    including AI-specific controls and standard enterprise controls.
    """
    
    def __init__(self):
        self.controls = {}
        self._initialize_control_catalog()
    
    def _initialize_control_catalog(self):
        """Initialize comprehensive control catalog"""
        
        # Access Control Controls
        self._add_control(SecurityControl(
            control_id="AC-001",
            name="User Access Management",
            description="Controls for managing user access to AI systems and data",
            category=ControlCategory.ACCESS_CONTROL,
            control_type=ControlType.PREVENTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.MANUAL_REVIEW],
            compliance_frameworks=["NIST", "ISO27001", "SOX"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        self._add_control(SecurityControl(
            control_id="AC-002", 
            name="Privileged Access Management",
            description="Controls for managing privileged access to AI model training and inference",
            category=ControlCategory.ACCESS_CONTROL,
            control_type=ControlType.PREVENTIVE,
            validation_methods=[ValidationMethod.CONFIGURATION_AUDIT, ValidationMethod.PENETRATION_TEST],
            compliance_frameworks=["NIST", "PCI-DSS"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        # Authentication Controls
        self._add_control(SecurityControl(
            control_id="AU-001",
            name="Multi-Factor Authentication",
            description="Multi-factor authentication for AI system access",
            category=ControlCategory.AUTHENTICATION,
            control_type=ControlType.PREVENTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.BEHAVIORAL_TEST],
            compliance_frameworks=["NIST", "ISO27001"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        # Data Protection Controls
        self._add_control(SecurityControl(
            control_id="DP-001",
            name="Data Encryption at Rest",
            description="Encryption of AI training data and model parameters at rest",
            category=ControlCategory.DATA_PROTECTION,
            control_type=ControlType.PREVENTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.CONFIGURATION_AUDIT],
            compliance_frameworks=["GDPR", "HIPAA", "PCI-DSS"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        self._add_control(SecurityControl(
            control_id="DP-002",
            name="Data Encryption in Transit", 
            description="Encryption of data during AI model training and inference",
            category=ControlCategory.DATA_PROTECTION,
            control_type=ControlType.PREVENTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.PENETRATION_TEST],
            compliance_frameworks=["GDPR", "HIPAA", "PCI-DSS"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        # AI-Specific Controls
        self._add_control(SecurityControl(
            control_id="AI-001",
            name="Model Input Validation",
            description="Validation and sanitization of inputs to AI models",
            category=ControlCategory.AI_SPECIFIC,
            control_type=ControlType.PREVENTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.BEHAVIORAL_TEST],
            compliance_frameworks=["EU AI Act", "NIST AI RMF"],
            criticality="High", 
            implementation_status="Implemented"
        ))
        
        self._add_control(SecurityControl(
            control_id="AI-002",
            name="Adversarial Attack Detection",
            description="Detection of adversarial examples and model manipulation",
            category=ControlCategory.AI_SPECIFIC,
            control_type=ControlType.DETECTIVE,
            validation_methods=[ValidationMethod.BEHAVIORAL_TEST, ValidationMethod.PENETRATION_TEST],
            compliance_frameworks=["EU AI Act", "NIST AI RMF"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        self._add_control(SecurityControl(
            control_id="AI-003",
            name="Model Integrity Monitoring",
            description="Continuous monitoring of AI model integrity and performance",
            category=ControlCategory.AI_SPECIFIC,
            control_type=ControlType.DETECTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.BEHAVIORAL_TEST],
            compliance_frameworks=["EU AI Act", "NIST AI RMF"],
            criticality="High",
            implementation_status="Implemented"
        ))
        
        # Monitoring Controls
        self._add_control(SecurityControl(
            control_id="MO-001",
            name="Security Event Monitoring",
            description="Continuous monitoring of security events in AI systems",
            category=ControlCategory.MONITORING,
            control_type=ControlType.DETECTIVE,
            validation_methods=[ValidationMethod.AUTOMATED_SCAN, ValidationMethod.MANUAL_REVIEW],
            compliance_frameworks=["NIST", "ISO27001"],
            criticality="High",
            implementation_status="Implemented"
        ))
    
    def _add_control(self, control: SecurityControl):
        """Add control to registry"""
        self.controls[control.control_id] = control
    
    def get_control(self, control_id: str) -> Optional[SecurityControl]:
        """Get control by ID"""
        return self.controls.get(control_id)
    
    def get_controls_by_category(self, category: ControlCategory) -> List[SecurityControl]:
        """Get all controls in a category"""
        return [control for control in self.controls.values() 
                if control.category == category]
    
    def get_critical_controls(self) -> List[SecurityControl]:
        """Get all critical controls"""
        return [control for control in self.controls.values() 
                if control.criticality == "High"]
    
    def get_all_controls(self) -> List[SecurityControl]:
        """Get all registered controls"""
        return list(self.controls.values())

class ControlValidationEngine:
    """
    Security control validation engine
    
    Executes comprehensive validation tests for security controls
    including automated scanning, manual review, and penetration testing.
    """
    
    def __init__(self):
        self.control_registry = SecurityControlRegistry()
        self.validation_tests = {}
        self._initialize_validation_tests()
    
    def _initialize_validation_tests(self):
        """Initialize validation test procedures"""
        
        # User Access Management Tests
        self._add_validation_test(ValidationTest(
            test_id="T-AC-001-001",
            control_id="AC-001",
            test_name="User Access Review",
            test_description="Review user access permissions and remove unnecessary access",
            validation_method=ValidationMethod.MANUAL_REVIEW,
            test_procedure="1. Extract user access list\n2. Review against job requirements\n3. Identify excessive permissions",
            expected_outcome="All users have minimum necessary access",
            automated=False
        ))
        
        self._add_validation_test(ValidationTest(
            test_id="T-AC-001-002", 
            control_id="AC-001",
            test_name="Automated Access Scan",
            test_description="Automated scan of user access configurations",
            validation_method=ValidationMethod.AUTOMATED_SCAN,
            test_procedure="Execute automated access audit tool",
            expected_outcome="No excessive permissions or orphaned accounts",
            automated=True
        ))
        
        # Privileged Access Management Tests
        self._add_validation_test(ValidationTest(
            test_id="T-AC-002-001",
            control_id="AC-002",
            test_name="Privileged Account Audit",
            test_description="Audit privileged accounts and their usage",
            validation_method=ValidationMethod.CONFIGURATION_AUDIT,
            test_procedure="1. Enumerate privileged accounts\n2. Review access logs\n3. Validate approval processes",
            expected_outcome="All privileged access is authorized and monitored",
            automated=False
        ))
        
        # Multi-Factor Authentication Tests
        self._add_validation_test(ValidationTest(
            test_id="T-AU-001-001",
            control_id="AU-001", 
            test_name="MFA Bypass Test",
            test_description="Test for MFA bypass vulnerabilities",
            validation_method=ValidationMethod.PENETRATION_TEST,
            test_procedure="Attempt to bypass MFA using various techniques",
            expected_outcome="MFA cannot be bypassed",
            automated=False
        ))
        
        # Data Encryption Tests
        self._add_validation_test(ValidationTest(
            test_id="T-DP-001-001",
            control_id="DP-001",
            test_name="Encryption Algorithm Validation",
            test_description="Validate encryption algorithms and key management",
            validation_method=ValidationMethod.CONFIGURATION_AUDIT,
            test_procedure="1. Review encryption configurations\n2. Validate key strength\n3. Test key rotation",
            expected_outcome="Strong encryption with proper key management",
            automated=True
        ))
        
        # AI-Specific Control Tests
        self._add_validation_test(ValidationTest(
            test_id="T-AI-001-001",
            control_id="AI-001",
            test_name="Input Validation Test",
            test_description="Test AI model input validation and sanitization",
            validation_method=ValidationMethod.BEHAVIORAL_TEST,
            test_procedure="1. Submit malicious inputs\n2. Test boundary conditions\n3. Validate error handling",
            expected_outcome="All malicious inputs are detected and rejected",
            automated=True
        ))
        
        self._add_validation_test(ValidationTest(
            test_id="T-AI-002-001",
            control_id="AI-002",
            test_name="Adversarial Example Detection",
            test_description="Test detection of adversarial examples",
            validation_method=ValidationMethod.BEHAVIORAL_TEST,
            test_procedure="1. Generate adversarial examples\n2. Submit to model\n3. Validate detection",
            expected_outcome="Adversarial examples are detected and flagged",
            automated=True
        ))
    
    def _add_validation_test(self, test: ValidationTest):
        """Add validation test"""
        if test.control_id not in self.validation_tests:
            self.validation_tests[test.control_id] = []
        self.validation_tests[test.control_id].append(test)
    
    async def validate_control(self, control_id: str) -> List[ValidationResult]:
        """Validate a specific security control"""
        
        control = self.control_registry.get_control(control_id)
        if not control:
            raise ValueError(f"Control {control_id} not found")
        
        tests = self.validation_tests.get(control_id, [])
        results = []
        
        for test in tests:
            print(f"ðŸ” Executing validation test: {test.test_name}")
            result = await self._execute_validation_test(test, control)
            results.append(result)
        
        return results
    
    async def validate_all_controls(self) -> Dict[str, List[ValidationResult]]:
        """Validate all security controls"""
        
        all_results = {}
        controls = self.control_registry.get_all_controls()
        
        for control in controls:
            print(f"ðŸ“‹ Validating control: {control.name}")
            results = await self.validate_control(control.control_id)
            all_results[control.control_id] = results
        
        return all_results
    
    async def validate_critical_controls(self) -> Dict[str, List[ValidationResult]]:
        """Validate only critical security controls"""
        
        critical_results = {}
        critical_controls = self.control_registry.get_critical_controls()
        
        for control in critical_controls:
            print(f"ðŸš¨ Validating critical control: {control.name}")
            results = await self.validate_control(control.control_id)
            critical_results[control.control_id] = results
        
        return critical_results
    
    async def _execute_validation_test(self, test: ValidationTest, 
                                     control: SecurityControl) -> ValidationResult:
        """Execute individual validation test"""
        
        try:
            if test.automated:
                result = await self._execute_automated_test(test, control)
            else:
                result = await self._execute_manual_test(test, control)
            
            return result
            
        except Exception as e:
            logger.error(f"Validation test {test.test_id} failed: {e}")
            
            return ValidationResult(
                test_id=test.test_id,
                control_id=test.control_id,
                validation_date=datetime.now(),
                status=ControlStatus.INEFFECTIVE,
                effectiveness_score=0.0,
                findings=[f"Test execution failed: {e}"],
                evidence={},
                recommendations=["Review and fix test execution"],
                remediation_priority="High"
            )
    
    async def _execute_automated_test(self, test: ValidationTest, 
                                    control: SecurityControl) -> ValidationResult:
        """Execute automated validation test"""
        
        # Simulate automated test execution
        print(f"  ðŸ¤– Running automated test: {test.test_name}")
        
        # Different test outcomes based on validation method
        if test.validation_method == ValidationMethod.AUTOMATED_SCAN:
            effectiveness_score = 85.0
            status = ControlStatus.EFFECTIVE
            findings = ["Automated scan completed successfully", "No critical issues found"]
            
        elif test.validation_method == ValidationMethod.BEHAVIORAL_TEST:
            effectiveness_score = 78.0
            status = ControlStatus.PARTIALLY_EFFECTIVE
            findings = ["Behavioral test passed most scenarios", "Minor edge cases require attention"]
            
        else:
            effectiveness_score = 92.0
            status = ControlStatus.EFFECTIVE
            findings = ["Automated validation successful"]
        
        recommendations = []
        if effectiveness_score < 80:
            recommendations.extend([
                "Review control configuration",
                "Implement additional monitoring"
            ])
        
        return ValidationResult(
            test_id=test.test_id,
            control_id=test.control_id,
            validation_date=datetime.now(),
            status=status,
            effectiveness_score=effectiveness_score,
            findings=findings,
            evidence={"test_output": "Automated test results", "scan_date": datetime.now().isoformat()},
            recommendations=recommendations,
            remediation_priority="Medium" if effectiveness_score < 80 else "Low"
        )
    
    async def _execute_manual_test(self, test: ValidationTest, 
                                 control: SecurityControl) -> ValidationResult:
        """Execute manual validation test"""
        
        # Simulate manual test execution
        print(f"  ðŸ‘¤ Running manual test: {test.test_name}")
        
        # Different outcomes based on control type
        if control.control_type == ControlType.PREVENTIVE:
            effectiveness_score = 88.0
            status = ControlStatus.EFFECTIVE
            findings = ["Manual review completed", "Control implementation verified"]
            
        elif control.control_type == ControlType.DETECTIVE:
            effectiveness_score = 82.0 
            status = ControlStatus.EFFECTIVE
            findings = ["Detection capabilities validated", "Response times acceptable"]
            
        else:
            effectiveness_score = 75.0
            status = ControlStatus.PARTIALLY_EFFECTIVE
            findings = ["Manual test partially successful", "Some gaps identified"]
        
        recommendations = []
        if effectiveness_score < 85:
            recommendations.extend([
                "Enhance control implementation",
                "Provide additional training"
            ])
        
        return ValidationResult(
            test_id=test.test_id,
            control_id=test.control_id,
            validation_date=datetime.now(),
            status=status,
            effectiveness_score=effectiveness_score,
            findings=findings,
            evidence={"reviewer": "Security Analyst", "review_date": datetime.now().isoformat()},
            recommendations=recommendations,
            remediation_priority="Medium" if effectiveness_score < 85 else "Low"
        )
    
    async def generate_validation_report(self, validation_results: Dict[str, List[ValidationResult]]) -> Dict[str, Any]:
        """Generate comprehensive validation report"""
        
        total_tests = sum(len(results) for results in validation_results.values())
        
        # Calculate overall metrics
        all_results = []
        for results in validation_results.values():
            all_results.extend(results)
        
        effective_tests = len([r for r in all_results if r.status == ControlStatus.EFFECTIVE])
        partially_effective = len([r for r in all_results if r.status == ControlStatus.PARTIALLY_EFFECTIVE])
        ineffective_tests = len([r for r in all_results if r.status == ControlStatus.INEFFECTIVE])
        
        avg_effectiveness = sum(r.effectiveness_score for r in all_results) / len(all_results) if all_results else 0
        
        # Control category analysis
        category_analysis = await self._analyze_by_category(validation_results)
        
        # Critical findings
        critical_findings = await self._identify_critical_findings(all_results)
        
        # Remediation priorities
        remediation_plan = await self._generate_remediation_plan(all_results)
        
        report = {
            "executive_summary": {
                "total_controls_tested": len(validation_results),
                "total_tests_executed": total_tests,
                "overall_effectiveness_score": avg_effectiveness,
                "effective_controls": effective_tests,
                "partially_effective_controls": partially_effective,
                "ineffective_controls": ineffective_tests
            },
            "control_effectiveness": {
                "effective_percentage": (effective_tests / total_tests * 100) if total_tests > 0 else 0,
                "partially_effective_percentage": (partially_effective / total_tests * 100) if total_tests > 0 else 0,
                "ineffective_percentage": (ineffective_tests / total_tests * 100) if total_tests > 0 else 0
            },
            "category_analysis": category_analysis,
            "critical_findings": critical_findings,
            "remediation_plan": remediation_plan,
            "compliance_status": await self._assess_compliance_status(validation_results),
            "recommendations": await self._generate_recommendations(all_results)
        }
        
        return report
    
    async def _analyze_by_category(self, validation_results: Dict[str, List[ValidationResult]]) -> Dict[str, Any]:
        """Analyze results by control category"""
        
        category_scores = {}
        
        for control_id, results in validation_results.items():
            control = self.control_registry.get_control(control_id)
            if control:
                category = control.category.value
                if category not in category_scores:
                    category_scores[category] = []
                
                avg_score = sum(r.effectiveness_score for r in results) / len(results) if results else 0
                category_scores[category].append(avg_score)
        
        # Calculate category averages
        category_analysis = {}
        for category, scores in category_scores.items():
            category_analysis[category] = {
                "average_effectiveness": sum(scores) / len(scores) if scores else 0,
                "control_count": len(scores),
                "status": "Good" if sum(scores) / len(scores) >= 80 else "Needs Improvement" if scores else "Unknown"
            }
        
        return category_analysis
    
    async def _identify_critical_findings(self, results: List[ValidationResult]) -> List[Dict[str, Any]]:
        """Identify critical findings requiring immediate attention"""
        
        critical_findings = []
        
        for result in results:
            if result.effectiveness_score < 70 or result.status == ControlStatus.INEFFECTIVE:
                control = self.control_registry.get_control(result.control_id)
                
                finding = {
                    "control_id": result.control_id,
                    "control_name": control.name if control else "Unknown",
                    "effectiveness_score": result.effectiveness_score,
                    "status": result.status.value,
                    "findings": result.findings,
                    "remediation_priority": result.remediation_priority
                }
                critical_findings.append(finding)
        
        # Sort by effectiveness score (lowest first)
        critical_findings.sort(key=lambda x: x["effectiveness_score"])
        
        return critical_findings
    
    async def _generate_remediation_plan(self, results: List[ValidationResult]) -> Dict[str, List[Dict[str, Any]]]:
        """Generate prioritized remediation plan"""
        
        remediation_plan = {
            "High": [],
            "Medium": [],
            "Low": []
        }
        
        for result in results:
            if result.recommendations:
                control = self.control_registry.get_control(result.control_id)
                
                remediation_item = {
                    "control_id": result.control_id,
                    "control_name": control.name if control else "Unknown",
                    "effectiveness_score": result.effectiveness_score,
                    "recommendations": result.recommendations,
                    "estimated_effort": "TBD"  # Would be calculated based on recommendations
                }
                
                priority = result.remediation_priority
                if priority in remediation_plan:
                    remediation_plan[priority].append(remediation_item)
        
        return remediation_plan
    
    async def _assess_compliance_status(self, validation_results: Dict[str, List[ValidationResult]]) -> Dict[str, Any]:
        """Assess compliance status against frameworks"""
        
        frameworks = ["NIST", "ISO27001", "GDPR", "EU AI Act"]
        compliance_status = {}
        
        for framework in frameworks:
            # Get controls that map to this framework
            framework_controls = [
                control for control in self.control_registry.get_all_controls()
                if framework in control.compliance_frameworks
            ]
            
            if framework_controls:
                # Calculate average effectiveness for framework controls
                framework_scores = []
                for control in framework_controls:
                    results = validation_results.get(control.control_id, [])
                    if results:
                        avg_score = sum(r.effectiveness_score for r in results) / len(results)
                        framework_scores.append(avg_score)
                
                if framework_scores:
                    compliance_score = sum(framework_scores) / len(framework_scores)
                    compliance_status[framework] = {
                        "compliance_score": compliance_score,
                        "status": "Compliant" if compliance_score >= 80 else "Non-Compliant",
                        "controls_assessed": len(framework_scores)
                    }
        
        return compliance_status
    
    async def _generate_recommendations(self, results: List[ValidationResult]) -> List[str]:
        """Generate high-level recommendations"""
        
        avg_effectiveness = sum(r.effectiveness_score for r in results) / len(results) if results else 0
        
        recommendations = []
        
        if avg_effectiveness < 70:
            recommendations.extend([
                "Immediate security control review and enhancement required",
                "Conduct comprehensive security architecture assessment",
                "Implement emergency remediation measures"
            ])
        elif avg_effectiveness < 80:
            recommendations.extend([
                "Strengthen security controls in identified areas",
                "Enhance monitoring and detection capabilities",
                "Conduct additional security training"
            ])
        else:
            recommendations.extend([
                "Maintain current security posture",
                "Consider advanced security enhancements",
                "Regular validation and continuous improvement"
            ])
        
        # AI-specific recommendations
        ai_results = [r for r in results if r.control_id.startswith("AI-")]
        if ai_results:
            ai_avg = sum(r.effectiveness_score for r in ai_results) / len(ai_results)
            if ai_avg < 85:
                recommendations.append("Enhance AI-specific security controls and monitoring")
        
        return recommendations

# Export main validation components
__all__ = ['SecurityControlRegistry', 'ControlValidationEngine', 'SecurityControl', 
           'ValidationTest', 'ValidationResult', 'ControlCategory', 'ControlStatus']
