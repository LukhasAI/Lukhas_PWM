"""
🧠 Enhanced Brain Integration System
LUKHlukhasS lukhasI Multi-Brain Symphony Architecture

This module provides a complete brain integration system that combines:
- Multi-Brain Symphony orchestration
- Emotional memory integration  
- Voice modulation
- Dream processing
- Advanced memory systems

Replaces and enhances the previous brain_integration.py with superior architecture.
"""

import asyncio
import logging
import time
import math
import json
import uuid
import threading
from typing import Dict, List, Any, Optional, Union, Set, Tuple
from datetime import datetime
from enum import Enum
import os

# Configure logging
logger = logging.getLogger("Enhanced.BrainIntegration")
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(name)s: %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Import MultiBrainSymphony components with fallback paths
try:
    from .MultiBrainSymphony import (
        MultiBrainSymphonyOrchestrator, 
        DreamsBrainSpecialist,
        MemoryBrainSpecialist, 
        LearningBrainSpecialist
    )
    SYMPHONY_AVAILABLE = True
except ImportError:
    try:
        from MultiBrainSymphony import (
            MultiBrainSymphonyOrchestrator, 
            DreamsBrainSpecialist,
            MemoryBrainSpecialist, 
            LearningBrainSpecialist
        )
        SYMPHONY_AVAILABLE = True
    except ImportError:
        logger.warning("MultiBrainSymphony not available, using fallback components")
        SYMPHONY_AVAILABLE = False

# Import new AI components from Lukhas repository integration
try:
    from .compliance.ai_compliance_manager import AIComplianceManager
    from .governance.dao_governance_node import DAOGovernanceNode
    from .ethics.ethical_hierarchy import EthicalHierarchy
    from .meta_cognitive.reflective_introspection_system import ReflectiveIntrospectionSystem
    from .reasoning.causal_reasoning_module import CausalReasoningModule
    from .memory.enhanced_memory_manager import EnhancedMemoryManager
    from .prediction.predictive_resource_manager import PredictiveResourceManager
    ADVANCED_AGI_COMPONENTS = True
except ImportError:
    try:
        from compliance.ai_compliance_manager import AIComplianceManager
        from governance.dao_governance_node import DAOGovernanceNode
        from ethics.ethical_hierarchy import EthicalHierarchy
        from meta_cognitive.reflective_introspection_system import ReflectiveIntrospectionSystem
        from reasoning.causal_reasoning_module import CausalReasoningModule
        from memory.enhanced_memory_manager import EnhancedMemoryManager
        from prediction.predictive_resource_manager import PredictiveResourceManager
        ADVANCED_AGI_COMPONENTS = True
    except ImportError:
        logger.warning("Advanced AI components not available, using fallback implementations")
        ADVANCED_AGI_COMPONENTS = False

# Import core components with fallbacks
try:
    from CORE.spine.fold_engine import AGIMemory, MemoryFold, MemoryType, MemoryPriority
except ImportError:
    logger.warning("Core memory components not available - using fallbacks")
    AGIMemory = None

try:
    from DASHBOARD.lukhas_as_agent.core.memory_folds import create_memory_fold, recall_memory_folds
except ImportError:
    logger.warning("Emotional memory folds not available")
    create_memory_fold = None
    recall_memory_folds = None

try:
    from VOICE.voice_integrator import VoiceIntegrator
except ImportError:
    VoiceIntegrator = None

try:
    from AID.dream_engine.dream_reflection_loop import DreamReflectionLoop
except ImportError:
    DreamReflectionLoop = None


# Import Lukhas_ID identity system
try:
    from ..Lukhas_ID import (
        unified_identity_manager,
        get_current_user,
        verify_tier_access,
        AccessTier,
        ConsentLevel
    )
    IDENTITY_AVAILABLE = True
    logger.info("Lukhas_ID Identity system loaded successfully")
except ImportError as e:
    logger.warning(f"Lukhas_ID Identity system not available: {e}")
    IDENTITY_AVAILABLE = False
    unified_identity_manager = None


class EnhancedEmotionalProcessor:
    """Enhanced emotional processing with vector operations and voice integration"""
    
    def __init__(self):
        self.emotion_vectors = {
            "neutral": [0.0, 0.0, 0.0],
            "joy": [0.8, 0.9, 0.3],
            "sadness": [-0.8, -0.7, -0.2],
            "anger": [-0.8, 0.7, 0.3],
            "fear": [-0.7, 0.8, 0.0],
            "trust": [0.7, 0.5, 0.2],
            "surprise": [0.0, 0.9, 0.8],
            "anticipation": [0.6, 0.8, 0.0],
        }
        
        self.current_state = {
            "primary_emotion": "neutral",
            "intensity": 0.5,
            "secondary_emotions": {},
            "last_updated": datetime.now().isoformat(),
            "stability": 0.8,
        }
        
        self.emotional_history = []
        self.max_history = 50
        
    def update_emotional_state(self, primary_emotion: str, intensity: float = None, 
                             secondary_emotions: Dict[str, float] = None, 
                             metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Update emotional state with enhanced tracking"""
        
        # Store previous state
        self.emotional_history.append(self.current_state.copy())
        if len(self.emotional_history) > self.max_history:
            self.emotional_history = self.emotional_history[-self.max_history:]
        
        # Update state
        if primary_emotion in self.emotion_vectors:
            self.current_state["primary_emotion"] = primary_emotion
            
        if intensity is not None:
            self.current_state["intensity"] = max(0.0, min(1.0, intensity))
            
        if secondary_emotions:
            valid_secondary = {
                e: max(0.0, min(1.0, i))
                for e, i in secondary_emotions.items()
                if e in self.emotion_vectors
            }
            self.current_state["secondary_emotions"] = valid_secondary
            
        self.current_state["last_updated"] = datetime.now().isoformat()
        
        # Calculate stability based on emotional change
        if self.emotional_history:
            previous = self.emotional_history[-1]
            distance = self._calculate_emotion_distance(
                previous["primary_emotion"], 
                self.current_state["primary_emotion"]
            )
            self.current_state["stability"] = max(0.1, 1.0 - (distance / 2.0))
            
        return self.current_state
    
    def _calculate_emotion_distance(self, emotion1: str, emotion2: str) -> float:
        """Calculate distance between emotions in vector space"""
        if emotion1 not in self.emotion_vectors:
            emotion1 = "neutral"
        if emotion2 not in self.emotion_vectors:
            emotion2 = "neutral"
            
        vec1 = self.emotion_vectors[emotion1]
        vec2 = self.emotion_vectors[emotion2]
        
        # Simple Euclidean distance
        distance = sum((a - b) ** 2 for a, b in zip(vec1, vec2)) ** 0.5
        return distance
    
    def get_voice_modulation_params(self) -> Dict[str, Any]:
        """Generate voice modulation parameters based on emotional state"""
        emotion = self.current_state["primary_emotion"]
        intensity = self.current_state["intensity"]
        
        emotion_adjustments = {
            "joy": {"pitch": 0.3, "speed": 0.2, "energy": 0.4},
            "sadness": {"pitch": -0.3, "speed": -0.25, "energy": -0.3},
            "anger": {"pitch": 0.2, "speed": 0.3, "energy": 0.5},
            "fear": {"pitch": 0.4, "speed": 0.4, "energy": 0.2},
            "surprise": {"pitch": 0.5, "speed": 0.1, "energy": 0.4},
            "trust": {"pitch": -0.1, "speed": -0.1, "energy": 0.1},
            "anticipation": {"pitch": 0.2, "speed": 0.1, "energy": 0.3}
        }
        
        adjustments = emotion_adjustments.get(emotion, {"pitch": 0, "speed": 0, "energy": 0})
        
        return {
            "pitch_adjustment": adjustments["pitch"] * intensity,
            "speed_adjustment": adjustments["speed"] * intensity,
            "energy_adjustment": adjustments["energy"] * intensity,
            "emphasis_level": 0.5 + (intensity * 0.3),
            "pause_threshold": 0.3 + ((1.0 - self.current_state["stability"]) * 0.2)
        }


class EnhancedMemorySystem:
    """Enhanced memory system with emotional integration and dream consolidation"""
    
    def __init__(self, emotional_processor: EnhancedEmotionalProcessor, memory_path: str = "./enhanced_memory"):
        self.emotional_processor = emotional_processor
        self.memory_path = memory_path
        os.makedirs(memory_path, exist_ok=True)
        
        self.memory_store = {}
        self.emotional_associations = {}
        self.consolidation_queue = []
        
        # Statistics
        self.stats = {
            "total_memories": 0,
            "emotional_memories": 0,
            "consolidations": 0,
            "retrievals": 0
        }
        
    def store_memory_with_emotion(self, key: str, content: Any, emotion: str = None, 
                                tags: List[str] = None, priority: str = "medium",
                                metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Store memory with emotional context"""
        
        # Use current emotional state if none provided
        if emotion is None:
            emotion = self.emotional_processor.current_state["primary_emotion"]
            
        memory_entry = {
            "key": key,
            "content": content,
            "emotion": emotion,
            "tags": tags or [],
            "priority": priority,
            "metadata": metadata or {},
            "timestamp": datetime.now().isoformat(),
            "access_count": 0,
            "emotional_intensity": self.emotional_processor.current_state["intensity"]
        }
        
        # Store in memory
        self.memory_store[key] = memory_entry
        
        # Create emotional associations
        if emotion not in self.emotional_associations:
            self.emotional_associations[emotion] = []
        self.emotional_associations[emotion].append(key)
        
        # Update statistics
        self.stats["total_memories"] += 1
        if emotion != "neutral":
            self.stats["emotional_memories"] += 1
            
        # Add to consolidation queue if high priority
        if priority in ["high", "critical"]:
            self.consolidation_queue.append(key)
            
        logger.info(f"Stored memory '{key}' with emotion '{emotion}'")
        
        return {
            "status": "success",
            "key": key,
            "emotion": emotion,
            "memory_id": str(uuid.uuid4()),
            "timestamp": memory_entry["timestamp"]
        }
    
    def retrieve_with_emotional_context(self, key: str = None, target_emotion: str = None,
                                      similarity_threshold: float = 0.7) -> Dict[str, Any]:
        """Retrieve memories with emotional context"""
        
        self.stats["retrievals"] += 1
        
        if key and key in self.memory_store:
            # Direct retrieval
            memory = self.memory_store[key]
            memory["access_count"] += 1
            return {
                "status": "success",
                "memory": memory,
                "retrieval_type": "direct"
            }
            
        elif target_emotion:
            # Emotional retrieval
            similar_memories = []
            
            for emotion, keys in self.emotional_associations.items():
                distance = self.emotional_processor._calculate_emotion_distance(target_emotion, emotion)
                if distance <= (2.0 - similarity_threshold * 2.0):  # Convert threshold to distance
                    for memory_key in keys:
                        memory = self.memory_store[memory_key]
                        memory["emotional_distance"] = distance
                        similar_memories.append(memory)
                        
            # Sort by emotional similarity and recency
            similar_memories.sort(key=lambda m: (m.get("emotional_distance", 1.0), m["timestamp"]))
            
            return {
                "status": "success",
                "memories": similar_memories[:10],  # Return top 10
                "retrieval_type": "emotional_similarity",
                "target_emotion": target_emotion
            }
            
        else:
            return {
                "status": "error",
                "message": "Either key or target_emotion must be provided"
            }
    
    def dream_consolidate_memories(self, max_memories: int = 50) -> Dict[str, Any]:
        """Consolidate memories through dream-like processing"""
        
        if not self.consolidation_queue:
            return {"status": "no_memories_to_consolidate"}
            
        consolidated_memories = []
        
        # Process memories in consolidation queue
        for key in self.consolidation_queue[:max_memories]:
            if key in self.memory_store:
                memory = self.memory_store[key]
                
                # Dream-like processing: create associations and strengthen important memories
                consolidated_memory = {
                    "original_key": key,
                    "content": memory["content"],
                    "emotion": memory["emotion"],
                    "consolidation_strength": memory["emotional_intensity"] * memory["access_count"],
                    "dream_associations": self._generate_dream_associations(memory),
                    "consolidated_at": datetime.now().isoformat()
                }
                
                consolidated_memories.append(consolidated_memory)
                
        # Clear processed items from queue
        self.consolidation_queue = self.consolidation_queue[max_memories:]
        self.stats["consolidations"] += len(consolidated_memories)
        
        logger.info(f"Consolidated {len(consolidated_memories)} memories through dream processing")
        
        return {
            "status": "success",
            "consolidated_count": len(consolidated_memories),
            "remaining_queue": len(self.consolidation_queue),
            "consolidated_memories": consolidated_memories
        }
    
    def _generate_dream_associations(self, memory: Dict[str, Any]) -> List[str]:
        """Generate dream-like associations for memory consolidation"""
        associations = []
        
        # Find emotionally similar memories
        emotion = memory["emotion"]
        if emotion in self.emotional_associations:
            similar_keys = self.emotional_associations[emotion][:3]  # Top 3 similar
            associations.extend([f"emotional_link_{key}" for key in similar_keys])
        
        # Add content-based associations (simplified)
        content_str = str(memory["content"]).lower()
        if "creative" in content_str:
            associations.append("creativity_network")
        if "memory" in content_str:
            associations.append("meta_memory_network")
        if "learning" in content_str:
            associations.append("learning_network")
            
        return associations


class EnhancedBrainIntegration:
    """
    Enhanced Brain Integration System combining Multi-Brain Symphony with 
    emotional memory processing, voice modulation, and dream consolidation.
    
    This is the superior replacement for the previous brain_integration.py
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the Enhanced Brain Integration System"""
        
        self.config = config or {}
        logger.info("🧠 Initializing Enhanced Brain Integration System")
        
        # Initialize core components
        self.emotional_processor = EnhancedEmotionalProcessor()
        self.memory_system = EnhancedMemorySystem(self.emotional_processor)
        
        # Initialize Multi-Brain Symphony if available
        if SYMPHONY_AVAILABLE:
            try:
                self.symphony_orchestrator = MultiBrainSymphonyOrchestrator(
                    emotional_oscillator=self.emotional_processor,
                    memory_integrator=self.memory_system
                )
                self.symphony_available = True
                logger.info("🎼 Multi-Brain Symphony orchestrator integrated")
            except Exception as e:
                logger.error(f"Failed to initialize symphony: {e}")
                self.symphony_orchestrator = None
                self.symphony_available = False
        else:
            self.symphony_orchestrator = None
            self.symphony_available = False
            
        # Initialize voice integration if available
        try:
            if VoiceIntegrator:
                self.voice_integrator = VoiceIntegrator()
            else:
                self.voice_integrator = None
        except Exception as e:
            logger.warning(f"Voice integrator not available: {e}")
            self.voice_integrator = None
            
        # Initialize dream engine if available
        try:
            if DreamReflectionLoop:
                self.dream_engine = DreamReflectionLoop()
            else:
                self.dream_engine = None
        except Exception as e:
            logger.warning(f"Dream engine not available: {e}")
            self.dream_engine = None

        # Initialize advanced AI components if available
        if ADVANCED_AGI_COMPONENTS:
            try:
                # Compliance and governance systems
                self.compliance_manager = AIComplianceManager(
                    region=self.config.get("region", "GLOBAL"),
                    level=self.config.get("compliance_level", "STRICT")
                )
                self.dao_governance = DAOGovernanceNode(agi_system=self)
                self.ethical_hierarchy = EthicalHierarchy()
                
                # Advanced cognitive systems
                self.meta_cognitive_system = ReflectiveIntrospectionSystem()
                self.causal_reasoning = CausalReasoningModule()
                self.enhanced_memory_manager = EnhancedMemoryManager()
                self.predictive_manager = PredictiveResourceManager()
                
                self.advanced_agi_available = True
                logger.info("🚀 Advanced AI components integrated successfully")
                
                # Initialize AI subsystems
                asyncio.create_task(self._initialize_agi_subsystems())
                
            except Exception as e:
                logger.error(f"Failed to initialize advanced AI components: {e}")
                self.advanced_agi_available = False
        else:
            self.advanced_agi_available = False
            logger.warning("⚠️  Advanced AI components not available")
            
        # Background processing
        self.consolidation_running = False
        self.consolidation_thread = None
        
        # Processing statistics
        self.stats = {
            "symphony_processes": 0,
            "emotional_updates": 0,
            "memory_operations": 0,
            "voice_outputs": 0,
            "dream_consolidations": 0,
            "compliance_checks": 0,
            "governance_decisions": 0,
            "ethical_evaluations": 0,
            "meta_cognitive_reflections": 0,
            "causal_inferences": 0,
            "memory_enhancements": 0,
            "predictive_operations": 0
        }
        
        logger.info("✅ Enhanced Brain Integration System initialized successfully")
    
    async def _initialize_agi_subsystems(self):
        """Initialize the advanced AI subsystems asynchronously"""
        if not self.advanced_agi_available:
            return
            
        try:
            # Initialize compliance manager
            if hasattr(self.compliance_manager, 'initialize'):
                await self.compliance_manager.initialize()
                
            # Initialize DAO governance  
            if hasattr(self.dao_governance, 'initialize'):
                await self.dao_governance.initialize()
                
            # Initialize ethical hierarchy
            if hasattr(self.ethical_hierarchy, 'initialize'):
                await self.ethical_hierarchy.initialize()
                
            # Initialize meta-cognitive system
            if hasattr(self.meta_cognitive_system, 'initialize'):
                await self.meta_cognitive_system.initialize()
                
            # Initialize causal reasoning
            if hasattr(self.causal_reasoning, 'initialize'):
                await self.causal_reasoning.initialize()
                
            # Initialize enhanced memory manager
            if hasattr(self.enhanced_memory_manager, 'initialize'):
                await self.enhanced_memory_manager.initialize()
                
            # Initialize predictive manager
            if hasattr(self.predictive_manager, 'initialize'):
                await self.predictive_manager.initialize()
                
            logger.info("🎯 Advanced AI subsystems initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize AI subsystems: {e}")
            self.advanced_agi_available = False
            
    async def process_with_agi_enhancement(self, input_data: Any, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Enhanced processing that integrates all AI components including
        compliance, governance, ethics, meta-cognitive, reasoning, memory, and prediction
        """
        context = context or {}
        start_time = time.time()
        
        # Initialize result structure
        result = {
            "status": "processing",
            "input_received": True,
            "timestamp": datetime.now().isoformat(),
            "processing_stages": {},
            "agi_enhancements": {}
        }
        
        try:
            # Stage 1: Compliance and Ethics Pre-Check
            if self.advanced_agi_available:
                # Compliance validation
                if hasattr(self, 'compliance_manager'):
                    compliance_result = await self.compliance_manager.validate_ai_action(
                        {"action": "process_input", "data": input_data}, context
                    )
                    result["agi_enhancements"]["compliance"] = compliance_result
                    self.stats["compliance_checks"] += 1
                    
                    # Block processing if critical compliance violation
                    if compliance_result.get("level") == "CRITICAL":
                        result["status"] = "blocked"
                        result["reason"] = "compliance_violation"
                        return result
                
                # Ethical evaluation
                if hasattr(self, 'ethical_hierarchy'):
                    ethical_result = await self.ethical_hierarchy.evaluate_ethical_decision(
                        input_data, context
                    )
                    result["agi_enhancements"]["ethics"] = ethical_result
                    self.stats["ethical_evaluations"] += 1
                    
                    # Warn if ethical concerns detected
                    if ethical_result.get("severity") in ["WARNING", "CRITICAL"]:
                        result["ethical_warnings"] = ethical_result.get("concerns", [])
            
            # Stage 2: Enhanced Memory and Context Processing
            if hasattr(self, 'enhanced_memory_manager'):
                memory_enhancement = await self.enhanced_memory_manager.process_with_context(
                    input_data, context
                )
                result["agi_enhancements"]["memory"] = memory_enhancement
                self.stats["memory_enhancements"] += 1
            
            # Stage 3: Meta-Cognitive Reflection
            if hasattr(self, 'meta_cognitive_system'):
                meta_reflection = await self.meta_cognitive_system.reflect_on_processing(
                    input_data, context, result
                )
                result["agi_enhancements"]["meta_cognitive"] = meta_reflection
                self.stats["meta_cognitive_reflections"] += 1
            
            # Stage 4: Causal Reasoning
            if hasattr(self, 'causal_reasoning'):
                causal_analysis = await self.causal_reasoning.analyze_causal_relationships(
                    input_data, context
                )
                result["agi_enhancements"]["causal_reasoning"] = causal_analysis
                self.stats["causal_inferences"] += 1
            
            # Stage 5: Predictive Resource Management
            if hasattr(self, 'predictive_manager'):
                predictive_insights = await self.predictive_manager.predict_resource_needs(
                    input_data, context, result
                )
                result["agi_enhancements"]["prediction"] = predictive_insights
                self.stats["predictive_operations"] += 1
            
            # Stage 6: Original Symphony Processing (if available)
            if self.symphony_available:
                symphony_result = await self.symphony_orchestrator.process_symphony(
                    input_data, context
                )
                result["processing_stages"]["symphony"] = symphony_result
                self.stats["symphony_processes"] += 1
            
            # Stage 7: Governance Decision Making (for major decisions)
            if self.advanced_agi_available and context.get("requires_governance", False):
                if hasattr(self, 'dao_governance'):
                    governance_result = await self.dao_governance.evaluate_decision(
                        input_data, context, result
                    )
                    result["agi_enhancements"]["governance"] = governance_result
                    self.stats["governance_decisions"] += 1
            
            # Stage 8: Integration and Final Processing
            result = await self._integrate_agi_results(result, input_data, context)
            
            # Update result status
            result["status"] = "completed"
            result["processing_time"] = time.time() - start_time
            result["agi_integration"] = "full" if self.advanced_agi_available else "partial"
            
            return result
            
        except Exception as e:
            logger.error(f"AI enhanced processing failed: {e}")
            result["status"] = "error"
            result["error"] = str(e)
            result["processing_time"] = time.time() - start_time
            return result
    
    async def _integrate_agi_results(self, result: Dict[str, Any], input_data: Any, context: Dict[str, Any]) -> Dict[str, Any]:
        """Integrate results from all AI components into a coherent response"""
        
        # Extract key insights from each component
        agi_insights = {
            "compliance_status": result.get("agi_enhancements", {}).get("compliance", {}).get("status", "unknown"),
            "ethical_alignment": result.get("agi_enhancements", {}).get("ethics", {}).get("alignment_score", 0.5),
            "memory_relevance": result.get("agi_enhancements", {}).get("memory", {}).get("relevance_score", 0.5),
            "causal_confidence": result.get("agi_enhancements", {}).get("causal_reasoning", {}).get("confidence", 0.5),
            "prediction_accuracy": result.get("agi_enhancements", {}).get("prediction", {}).get("accuracy", 0.5),
            "meta_awareness": result.get("agi_enhancements", {}).get("meta_cognitive", {}).get("awareness_level", 0.5)
        }
        
        # Calculate overall AI intelligence score
        agi_score = sum(agi_insights.values()) / len(agi_insights)
        
        # Generate integrated recommendations
        recommendations = []
        if agi_insights["compliance_status"] != "compliant":
            recommendations.append("Review compliance requirements")
        if agi_insights["ethical_alignment"] < 0.7:
            recommendations.append("Consider ethical implications")
        if agi_insights["causal_confidence"] < 0.6:
            recommendations.append("Gather more causal evidence")
        
        result["agi_summary"] = {
            "overall_score": agi_score,
            "insights": agi_insights,
            "recommendations": recommendations,
            "integration_complete": True
        }
        
        return result
