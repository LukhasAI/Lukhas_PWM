"""
Adaptive Reasoning Loop
Dynamic reasoning system that adapts strategies based on context and feedback
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from enum import Enum
import json

logger = logging.getLogger(__name__)


class ReasoningStrategy(Enum):
    """Available reasoning strategies"""
    DEDUCTIVE = "deductive"
    INDUCTIVE = "inductive"
    ABDUCTIVE = "abductive"
    ANALOGICAL = "analogical"
    CAUSAL = "causal"
    PROBABILISTIC = "probabilistic"
    SYMBOLIC = "symbolic"
    HYBRID = "hybrid"


class ReasoningContext:
    """Context for reasoning operations"""

    def __init__(self, query: str, domain: str = "general", constraints: Dict[str, Any] = None):
        self.query = query
        self.domain = domain
        self.constraints = constraints or {}
        self.history = []
        self.metadata = {
            "created_at": datetime.now().isoformat(),
            "iterations": 0,
            "strategies_used": []
        }


class AdaptiveReasoningLoop:
    """
    Adaptive reasoning system that dynamically selects and combines
    reasoning strategies based on context and performance
    """

    def __init__(self):
        self.active = False
        self.current_strategy = ReasoningStrategy.HYBRID
        self.strategy_weights = {
            ReasoningStrategy.DEDUCTIVE: 0.2,
            ReasoningStrategy.INDUCTIVE: 0.2,
            ReasoningStrategy.ABDUCTIVE: 0.15,
            ReasoningStrategy.ANALOGICAL: 0.15,
            ReasoningStrategy.CAUSAL: 0.1,
            ReasoningStrategy.PROBABILISTIC: 0.1,
            ReasoningStrategy.SYMBOLIC: 0.1
        }
        self.performance_history = []
        self.adaptation_threshold = 0.7
        self.max_iterations = 10

    async def start_reasoning(self, context: ReasoningContext) -> Dict[str, Any]:
        """Start adaptive reasoning process"""
        self.active = True
        logger.info(f"Starting adaptive reasoning for: {context.query}")

        result = {
            "query": context.query,
            "status": "started",
            "reasoning_path": [],
            "conclusion": None,
            "confidence": 0.0
        }

        try:
            # Select initial strategy
            strategy = self._select_strategy(context)

            # Execute reasoning loop
            for iteration in range(self.max_iterations):
                if not self.active:
                    break

                context.metadata["iterations"] = iteration + 1

                # Apply current strategy
                step_result = await self._apply_strategy(strategy, context)
                result["reasoning_path"].append(step_result)

                # Evaluate performance
                performance = self._evaluate_performance(step_result)

                # Check if we've reached a conclusion
                if performance > self.adaptation_threshold:
                    result["conclusion"] = step_result["conclusion"]
                    result["confidence"] = performance
                    result["status"] = "completed"
                    break

                # Adapt strategy if needed
                strategy = self._adapt_strategy(strategy, performance, context)

            if result["status"] != "completed":
                result["status"] = "max_iterations_reached"

        except Exception as e:
            logger.error(f"Reasoning error: {e}")
            result["status"] = "error"
            result["error"] = str(e)

        self.active = False
        return result

    def _select_strategy(self, context: ReasoningContext) -> ReasoningStrategy:
        """Select initial reasoning strategy based on context"""
        # Domain-specific strategy selection
        domain_strategies = {
            "mathematical": ReasoningStrategy.DEDUCTIVE,
            "scientific": ReasoningStrategy.INDUCTIVE,
            "diagnostic": ReasoningStrategy.ABDUCTIVE,
            "creative": ReasoningStrategy.ANALOGICAL,
            "predictive": ReasoningStrategy.PROBABILISTIC,
            "logical": ReasoningStrategy.SYMBOLIC,
            "general": ReasoningStrategy.HYBRID
        }

        selected = domain_strategies.get(context.domain, ReasoningStrategy.HYBRID)
        context.metadata["strategies_used"].append(selected.value)
        return selected

    async def _apply_strategy(self, strategy: ReasoningStrategy, context: ReasoningContext) -> Dict[str, Any]:
        """Apply a specific reasoning strategy"""
        step_result = {
            "strategy": strategy.value,
            "timestamp": datetime.now().isoformat(),
            "input": context.query,
            "process": [],
            "conclusion": None,
            "confidence": 0.0
        }

        if strategy == ReasoningStrategy.DEDUCTIVE:
            step_result = await self._deductive_reasoning(context, step_result)
        elif strategy == ReasoningStrategy.INDUCTIVE:
            step_result = await self._inductive_reasoning(context, step_result)
        elif strategy == ReasoningStrategy.ABDUCTIVE:
            step_result = await self._abductive_reasoning(context, step_result)
        elif strategy == ReasoningStrategy.ANALOGICAL:
            step_result = await self._analogical_reasoning(context, step_result)
        elif strategy == ReasoningStrategy.CAUSAL:
            step_result = await self._causal_reasoning(context, step_result)
        elif strategy == ReasoningStrategy.PROBABILISTIC:
            step_result = await self._probabilistic_reasoning(context, step_result)
        elif strategy == ReasoningStrategy.SYMBOLIC:
            step_result = await self._symbolic_reasoning(context, step_result)
        else:  # HYBRID
            step_result = await self._hybrid_reasoning(context, step_result)

        return step_result

    async def _deductive_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply deductive reasoning: general principles to specific conclusions"""
        result["process"].append("Applying general rules to specific case")

        # Simulate deductive process
        if "if" in context.query.lower() and "then" in context.query.lower():
            result["conclusion"] = "Logical implication identified"
            result["confidence"] = 0.9
        else:
            result["conclusion"] = "Deductive pattern analysis in progress"
            result["confidence"] = 0.6

        return result

    async def _inductive_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply inductive reasoning: specific observations to general principles"""
        result["process"].append("Generalizing from specific examples")

        # Simulate inductive process
        if "pattern" in context.query.lower() or "trend" in context.query.lower():
            result["conclusion"] = "Pattern identified through observation"
            result["confidence"] = 0.85
        else:
            result["conclusion"] = "Gathering more examples for generalization"
            result["confidence"] = 0.5

        return result

    async def _abductive_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply abductive reasoning: best explanation for observations"""
        result["process"].append("Finding best explanation for observations")

        # Simulate abductive process
        if "why" in context.query.lower() or "explain" in context.query.lower():
            result["conclusion"] = "Most likely explanation identified"
            result["confidence"] = 0.8
        else:
            result["conclusion"] = "Generating hypotheses"
            result["confidence"] = 0.55

        return result

    async def _analogical_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply analogical reasoning: reasoning by comparison"""
        result["process"].append("Finding similar cases for comparison")

        # Simulate analogical process
        if "like" in context.query.lower() or "similar" in context.query.lower():
            result["conclusion"] = "Relevant analogy identified"
            result["confidence"] = 0.75
        else:
            result["conclusion"] = "Searching for analogous situations"
            result["confidence"] = 0.45

        return result

    async def _causal_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply causal reasoning: understanding cause and effect"""
        result["process"].append("Analyzing causal relationships")

        # Simulate causal process
        if "cause" in context.query.lower() or "effect" in context.query.lower():
            result["conclusion"] = "Causal chain identified"
            result["confidence"] = 0.82
        else:
            result["conclusion"] = "Tracing causal connections"
            result["confidence"] = 0.58

        return result

    async def _probabilistic_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply probabilistic reasoning: reasoning under uncertainty"""
        result["process"].append("Calculating probabilities and uncertainties")

        # Simulate probabilistic process
        if "probability" in context.query.lower() or "likely" in context.query.lower():
            result["conclusion"] = "Probability distribution calculated"
            result["confidence"] = 0.78
        else:
            result["conclusion"] = "Assessing likelihood of outcomes"
            result["confidence"] = 0.65

        return result

    async def _symbolic_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply symbolic reasoning: formal logic and symbol manipulation"""
        result["process"].append("Applying formal symbolic logic")

        # Simulate symbolic process
        if any(symbol in context.query for symbol in ["∀", "∃", "→", "¬", "∧", "∨"]):
            result["conclusion"] = "Symbolic proof completed"
            result["confidence"] = 0.95
        else:
            result["conclusion"] = "Converting to symbolic representation"
            result["confidence"] = 0.7

        return result

    async def _hybrid_reasoning(self, context: ReasoningContext, result: Dict[str, Any]) -> Dict[str, Any]:
        """Apply hybrid reasoning: combining multiple strategies"""
        result["process"].append("Combining multiple reasoning strategies")

        # Combine weighted strategies
        sub_results = []
        for strategy, weight in self.strategy_weights.items():
            if strategy != ReasoningStrategy.HYBRID and weight > 0.1:
                sub_result = await self._apply_strategy(strategy, context)
                sub_results.append((sub_result, weight))

        # Aggregate results
        total_confidence = sum(r["confidence"] * w for r, w in sub_results)
        result["conclusion"] = "Hybrid analysis complete"
        result["confidence"] = min(total_confidence, 0.9)
        result["sub_strategies"] = [r["strategy"] for r, _ in sub_results]

        return result

    def _evaluate_performance(self, step_result: Dict[str, Any]) -> float:
        """Evaluate the performance of a reasoning step"""
        # Simple evaluation based on confidence and completeness
        confidence = step_result.get("confidence", 0.0)
        has_conclusion = step_result.get("conclusion") is not None

        performance = confidence * (1.0 if has_conclusion else 0.5)
        self.performance_history.append(performance)

        return performance

    def _adapt_strategy(self, current_strategy: ReasoningStrategy, performance: float, context: ReasoningContext) -> ReasoningStrategy:
        """Adapt reasoning strategy based on performance"""
        if performance < 0.3:
            # Poor performance - try a different strategy
            unused_strategies = [s for s in ReasoningStrategy
                               if s.value not in context.metadata["strategies_used"]]
            if unused_strategies:
                new_strategy = unused_strategies[0]
                context.metadata["strategies_used"].append(new_strategy.value)
                logger.info(f"Adapting strategy from {current_strategy.value} to {new_strategy.value}")
                return new_strategy

        elif performance < 0.6:
            # Moderate performance - adjust weights in hybrid mode
            self._adjust_weights(current_strategy, performance)
            return ReasoningStrategy.HYBRID

        # Good performance - continue with current strategy
        return current_strategy

    def _adjust_weights(self, strategy: ReasoningStrategy, performance: float):
        """Adjust strategy weights based on performance"""
        if strategy in self.strategy_weights:
            # Increase weight for better performing strategies
            adjustment = (performance - 0.5) * 0.1
            self.strategy_weights[strategy] = max(0.05, min(0.4,
                self.strategy_weights[strategy] + adjustment))

            # Normalize weights
            total = sum(self.strategy_weights.values())
            for key in self.strategy_weights:
                self.strategy_weights[key] /= total

    def stop_reasoning(self):
        """Stop the reasoning loop"""
        self.active = False
        logger.info("Adaptive reasoning loop stopped")
        return {"status": "stopped", "iterations": len(self.performance_history)}

    def get_status(self) -> Dict[str, Any]:
        """Get current reasoning loop status"""
        return {
            "active": self.active,
            "current_strategy": self.current_strategy.value,
            "strategy_weights": {k.value: v for k, v in self.strategy_weights.items()},
            "performance_history": self.performance_history[-10:],  # Last 10 performances
            "adaptation_threshold": self.adaptation_threshold
        }

    def reset(self):
        """Reset the reasoning loop to initial state"""
        self.active = False
        self.performance_history = []
        # Reset weights to uniform
        for key in self.strategy_weights:
            self.strategy_weights[key] = 1.0 / len(self.strategy_weights)


# Factory function for backward compatibility
def create_reasoning_loop():
    """Create and return an adaptive reasoning loop instance"""
    return AdaptiveReasoningLoop()