{
  "privacy": {
    "status": "present",
    "files": [
      {
        "path": "privacy/zkp_dream_validator.py",
        "size": 39160,
        "lines": 955,
        "functions": [
          "__init__",
          "_default_config",
          "_initialize_cryptographic_keys",
          "_initialize_pedersen_commitment",
          "_initialize_bulletproof_parameters",
          "_create_pedersen_commitment",
          "_generate_range_proof",
          "_generate_compliance_proof",
          "_generate_safety_proof",
          "_encrypt_sensitive_data",
          "_decrypt_sensitive_data",
          "_verify_proof_structure",
          "_validate_emotional_range_proof",
          "_validate_ethical_compliance_proof",
          "_validate_trauma_processing_proof",
          "_generate_proof_id",
          "_generate_proof_hash",
          "_generate_validator_signature",
          "_hash_user_id",
          "_hash_dream_id",
          "_get_validator_id",
          "_add_audit_entry",
          "get_validator_status"
        ],
        "classes": [
          "ZKPProofType",
          "ZKPValidationLevel",
          "ZKPProof",
          "ZKPValidationResult",
          "ZKPDreamValidator"
        ],
        "security_score": 11
      }
    ],
    "functions": [
      "zkp_dream_validator.py:__init__",
      "zkp_dream_validator.py:_default_config",
      "zkp_dream_validator.py:_initialize_cryptographic_keys",
      "zkp_dream_validator.py:_initialize_pedersen_commitment",
      "zkp_dream_validator.py:_initialize_bulletproof_parameters",
      "zkp_dream_validator.py:_create_pedersen_commitment",
      "zkp_dream_validator.py:_generate_range_proof",
      "zkp_dream_validator.py:_generate_compliance_proof",
      "zkp_dream_validator.py:_generate_safety_proof",
      "zkp_dream_validator.py:_encrypt_sensitive_data",
      "zkp_dream_validator.py:_decrypt_sensitive_data",
      "zkp_dream_validator.py:_verify_proof_structure",
      "zkp_dream_validator.py:_validate_emotional_range_proof",
      "zkp_dream_validator.py:_validate_ethical_compliance_proof",
      "zkp_dream_validator.py:_validate_trauma_processing_proof",
      "zkp_dream_validator.py:_generate_proof_id",
      "zkp_dream_validator.py:_generate_proof_hash",
      "zkp_dream_validator.py:_generate_validator_signature",
      "zkp_dream_validator.py:_hash_user_id",
      "zkp_dream_validator.py:_hash_dream_id",
      "zkp_dream_validator.py:_get_validator_id",
      "zkp_dream_validator.py:_add_audit_entry",
      "zkp_dream_validator.py:get_validator_status"
    ],
    "classes": [
      "zkp_dream_validator.py:ZKPProofType",
      "zkp_dream_validator.py:ZKPValidationLevel",
      "zkp_dream_validator.py:ZKPProof",
      "zkp_dream_validator.py:ZKPValidationResult",
      "zkp_dream_validator.py:ZKPDreamValidator"
    ],
    "total_lines": 955,
    "security_keywords": 11
  },
  "security": {
    "status": "present",
    "files": [
      {
        "path": "security/__init__.py",
        "size": 307,
        "lines": 13,
        "functions": [],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "security/hardware_root.py",
        "size": 790,
        "lines": 25,
        "functions": [
          "__init__",
          "store_key",
          "retrieve_key"
        ],
        "classes": [
          "HardwareRoot"
        ],
        "security_score": 0
      },
      {
        "path": "security/moderator.py",
        "size": 1534,
        "lines": 45,
        "functions": [
          "__init__",
          "is_emotionally_intense",
          "is_compliant",
          "__init__",
          "respond"
        ],
        "classes": [
          "SymbolicComplianceRules",
          "ModerationWrapper"
        ],
        "security_score": 2
      }
    ],
    "functions": [
      "hardware_root.py:__init__",
      "hardware_root.py:store_key",
      "hardware_root.py:retrieve_key",
      "moderator.py:__init__",
      "moderator.py:is_emotionally_intense",
      "moderator.py:is_compliant",
      "moderator.py:__init__",
      "moderator.py:respond"
    ],
    "classes": [
      "hardware_root.py:HardwareRoot",
      "moderator.py:SymbolicComplianceRules",
      "moderator.py:ModerationWrapper"
    ],
    "total_lines": 83,
    "security_keywords": 3
  },
  "compliance": {
    "status": "present",
    "files": [
      {
        "path": "compliance/symbolic_governance_checker.py",
        "size": 0,
        "lines": 1,
        "functions": [],
        "classes": [],
        "security_score": 0
      }
    ],
    "functions": [],
    "classes": [],
    "total_lines": 1,
    "security_keywords": 0
  },
  "ethics": {
    "status": "present",
    "files": [
      {
        "path": "ethics/ethical_safety_alignment.py",
        "size": 3672,
        "lines": 89,
        "functions": [],
        "classes": [],
        "security_score": 8
      },
      {
        "path": "ethics/compliance_engine.py",
        "size": 36407,
        "lines": 900,
        "functions": [
          "__init__",
          "anonymize_metadata",
          "should_retain_data",
          "check_voice_data_compliance",
          "validate_content_against_ethical_constraints",
          "generate_compliance_report",
          "_generate_anonymous_id",
          "get_compliance_status",
          "detect_regulatory_region",
          "update_compliance_settings",
          "get_audit_trail",
          "_initialize_ethical_framework",
          "_evaluate_bias",
          "_evaluate_transparency",
          "_evaluate_privacy",
          "_evaluate_harm",
          "_evaluate_oversight",
          "_evaluate_autonomy",
          "_evaluate_value_alignment",
          "_analyze_text_content",
          "_apply_differential_privacy",
          "_get_applicable_regulations",
          "_apply_region_specific_rules",
          "_map_location_string_to_region",
          "_record_audit",
          "check_module_compliance",
          "add_laplace_noise"
        ],
        "classes": [
          "ComplianceEngine"
        ],
        "security_score": 11
      },
      {
        "path": "ethics/service.py",
        "size": 16734,
        "lines": 439,
        "functions": [
          "assess_action",
          "check_compliance",
          "evaluate_safety",
          "__init__",
          "assess_action",
          "check_compliance",
          "evaluate_safety",
          "audit_decision",
          "_load_ethics_rules",
          "_evaluate_action_ethics",
          "_check_regulation_compliance",
          "_assess_operation_safety",
          "_get_ethics_version",
          "verify_user_access",
          "check_consent",
          "log_activity"
        ],
        "classes": [
          "EthicsService",
          "IdentityClient"
        ],
        "security_score": 5
      },
      {
        "path": "ethics/tracing.py",
        "size": 0,
        "lines": 1,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/policy_validator.py",
        "size": 7761,
        "lines": 213,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/meta_ethics_governor.py",
        "size": 30595,
        "lines": 779,
        "functions": [
          "ethical_checkpoint",
          "__init__",
          "load_principles",
          "add_principle",
          "__init__",
          "_load_default_principles",
          "_check_principle_conditions",
          "_check_violation",
          "load_principles",
          "__init__",
          "_load_default_principles",
          "load_principles",
          "__init__",
          "_initialize_default_engines",
          "_load_cultural_adapters",
          "add_ethical_engine",
          "add_event_callback",
          "get_human_review_queue",
          "resolve_human_review",
          "get_status",
          "decorator",
          "instrument_reasoning",
          "get_srd"
        ],
        "classes": [
          "EthicalFramework",
          "EthicalVerdict",
          "Severity",
          "CulturalContext",
          "EthicalPrinciple",
          "EthicalDecision",
          "EthicalEvaluation",
          "EthicalFrameworkEngine",
          "DeontologicalEngine",
          "ConsequentialistEngine",
          "MetaEthicsGovernor"
        ],
        "security_score": 6
      },
      {
        "path": "ethics/policy_engine.py",
        "size": 7719,
        "lines": 213,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/monitor.py",
        "size": 3564,
        "lines": 109,
        "functions": [
          "ethics_drift_detect",
          "log_ethics_event",
          "log_self_reflection",
          "self_reflection_report"
        ],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "ethics/ethical_guardian.py",
        "size": 3356,
        "lines": 68,
        "functions": [
          "ethical_check"
        ],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/oscillating_conscience.py",
        "size": 781,
        "lines": 25,
        "functions": [
          "__init__",
          "update"
        ],
        "classes": [
          "OscillatingConscience"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/compliance.py",
        "size": 7963,
        "lines": 207,
        "functions": [
          "__init__",
          "get_plugin_risk_score",
          "get_violation_history",
          "get_compliance_report",
          "_contains_sensitive_data",
          "_update_plugin_risk_score"
        ],
        "classes": [
          "EthicsViolationType",
          "ComplianceFramework",
          "ComplianceViolation",
          "EthicsValidationResult",
          "EthicsComplianceEngine"
        ],
        "security_score": 7
      },
      {
        "path": "ethics/governance_engine.py",
        "size": 15448,
        "lines": 396,
        "functions": [],
        "classes": [],
        "security_score": 5
      },
      {
        "path": "ethics/intrinsic_governor.py",
        "size": 633,
        "lines": 17,
        "functions": [
          "__init__"
        ],
        "classes": [
          "IntrinsicEthicalGovernor"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/compliance_engine20250503213400_p95.py",
        "size": 8437,
        "lines": 223,
        "functions": [
          "__init__",
          "anonymize_metadata",
          "should_retain_data",
          "check_voice_data_compliance",
          "validate_content_against_ethical_constraints",
          "generate_compliance_report",
          "_generate_anonymous_id",
          "get_compliance_status"
        ],
        "classes": [
          "Complianceengine"
        ],
        "security_score": 6
      },
      {
        "path": "ethics/compliance_simple.py",
        "size": 7964,
        "lines": 207,
        "functions": [
          "__init__",
          "get_plugin_risk_score",
          "get_violation_history",
          "get_compliance_report",
          "_contains_sensitive_data",
          "_update_plugin_risk_score"
        ],
        "classes": [
          "EthicsViolationType",
          "ComplianceFramework",
          "ComplianceViolation",
          "EthicsValidationResult",
          "EthicsComplianceEngine"
        ],
        "security_score": 7
      },
      {
        "path": "ethics/batch_guard.py",
        "size": 11967,
        "lines": 289,
        "functions": [
          "create_ethics_guard",
          "__init__",
          "validate_batch_ethics",
          "_validate_single_task_ethics",
          "_contains_sensitive_data",
          "_detect_harmful_content",
          "_has_ai_disclosure",
          "_validate_symbol_compliance",
          "_determine_required_badges",
          "generate_ethics_report"
        ],
        "classes": [
          "EthicsLevel",
          "ComplianceStatus",
          "EthicsResult",
          "EthicsBatchGuard"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/tier_enforcer.py",
        "size": 1643,
        "lines": 66,
        "functions": [
          "tier_required",
          "collapse_kernel",
          "decorator",
          "wrapper"
        ],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "ethics/policy_manager.py",
        "size": 5611,
        "lines": 141,
        "functions": [
          "determine_active_regulations",
          "log_active_regulations"
        ],
        "classes": [],
        "security_score": 4
      },
      {
        "path": "ethics/simplified_ethics_integration.py",
        "size": 5115,
        "lines": 148,
        "functions": [
          "get_ethics_integration",
          "__init__",
          "get_ethics_status"
        ],
        "classes": [
          "SimplifiedEthicsIntegration"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/audit_ethics_monitor.py",
        "size": 1410,
        "lines": 47,
        "functions": [
          "main"
        ],
        "classes": [],
        "security_score": 2
      },
      {
        "path": "ethics/ethical_drift_detector.py",
        "size": 13695,
        "lines": 358,
        "functions": [
          "load_ethics_config",
          "calculate_weighted_drift_score",
          "apply_violation_tagging",
          "_calculate_violation_severity",
          "_classify_symbolically",
          "check_escalation_requirements",
          "enrich_trace_metadata",
          "export_ethics_report",
          "detect_ethical_drift",
          "_generate_recommendation",
          "_send_real_time_alerts",
          "get_system_capabilities",
          "generate_collapse_hash",
          "crypto_trace_index"
        ],
        "classes": [],
        "security_score": 6
      },
      {
        "path": "ethics/__init__.py",
        "size": 36116,
        "lines": 543,
        "functions": [
          "__getattr__",
          "__dir__"
        ],
        "classes": [],
        "security_score": 11
      },
      {
        "path": "ethics/community_feedback.py",
        "size": 559,
        "lines": 22,
        "functions": [
          "load_rules",
          "save_rules",
          "apply_proposal"
        ],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "ethics/redteam_sim.py",
        "size": 3151,
        "lines": 107,
        "functions": [
          "parse_prompts_from_file",
          "run_redteam_simulation",
          "main",
          "__hash__"
        ],
        "classes": [
          "HashableDict"
        ],
        "security_score": 2
      },
      {
        "path": "ethics/_spikethickness.py",
        "size": 537,
        "lines": 18,
        "functions": [
          "__init__"
        ],
        "classes": [
          "SpikethicknessValidator"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/decision_node.py",
        "size": 30298,
        "lines": 776,
        "functions": [
          "__init__",
          "_initialize_principles",
          "_healthcare_principles",
          "_finance_principles",
          "_content_moderation_principles",
          "evaluate_action",
          "_evaluate_principle",
          "_apply_context_adjustments",
          "_select_framework",
          "_generate_explanation",
          "_generate_alternatives",
          "_add_privacy_protections",
          "_add_transparency",
          "_add_user_choice",
          "_add_safety_measures",
          "_add_human_oversight",
          "_record_decision",
          "_log_audit_event",
          "get_principle_weights",
          "set_principle_weight",
          "analyze_ethical_trends",
          "evaluate_content",
          "_identify_content_issues",
          "process_message"
        ],
        "classes": [
          "EthicsNode"
        ],
        "security_score": 11
      },
      {
        "path": "ethics/ethics_guard.py",
        "size": 10679,
        "lines": 319,
        "functions": [
          "__init__",
          "_load_default_rules",
          "check_content_safety",
          "check_privacy_compliance",
          "ethical_review",
          "comprehensive_compliance_check",
          "get_compliance_report",
          "update_rules",
          "_generate_recommendation",
          "anonymize_data"
        ],
        "classes": [
          "LegalComplianceAssistant"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/export_report.py",
        "size": 19112,
        "lines": 444,
        "functions": [
          "export_ethics_report",
          "export_comprehensive_ethics_report",
          "__init__",
          "export_multi_format",
          "_export_json",
          "_export_yaml",
          "_export_csv",
          "_export_html",
          "_generate_html_report",
          "generate_dashboard_data",
          "_group_violations_by_severity",
          "_group_violations_by_attribute",
          "generate_audit_trail",
          "generate_governance_summary",
          "_generate_governance_recommendations"
        ],
        "classes": [
          "EthicsReportExporter"
        ],
        "security_score": 5
      },
      {
        "path": "ethics/quantum_mesh_integrator.py",
        "size": 29800,
        "lines": 736,
        "functions": [
          "__post_init__",
          "__init__",
          "_load_config",
          "integrate_ethics_mesh",
          "calculate_phase_entanglement_matrix",
          "detect_ethics_phase_conflict",
          "_calculate_weighted_coherence",
          "_calculate_weighted_confidence",
          "_calculate_weighted_entropy",
          "_calculate_weighted_alignment",
          "_calculate_phase_synchronization",
          "_calculate_stability_index",
          "_calculate_drift_magnitude",
          "_assess_risk_level",
          "_get_expected_entanglement",
          "_assess_cascade_risk",
          "_identify_cascade_triggers",
          "_create_drift_signal",
          "_recommend_intervention",
          "get_mesh_status"
        ],
        "classes": [
          "EthicsRiskLevel",
          "EthicsSignalType",
          "EthicalState",
          "EthicsSignal",
          "PhaseEntanglement",
          "QuantumEthicsMeshIntegrator"
        ],
        "security_score": 2
      },
      {
        "path": "ethics/ethical_auditor.py",
        "size": 20038,
        "lines": 515,
        "functions": [
          "__init__",
          "_generate_system_prompt",
          "_generate_user_prompt",
          "_parse_audit_response",
          "_calculate_cost",
          "_generate_audit_hash",
          "_sign_with_lambda_id",
          "get_audit_summary"
        ],
        "classes": [
          "AuditContext",
          "AuditResult",
          "EliteEthicalAuditor"
        ],
        "security_score": 8
      },
      {
        "path": "ethics/engine.py",
        "size": 855,
        "lines": 31,
        "functions": [
          "__init__",
          "evaluate",
          "interpret_score"
        ],
        "classes": [
          "EthicsEngine"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/guardian.py",
        "size": 524,
        "lines": 24,
        "functions": [
          "assess_risk"
        ],
        "classes": [
          "DefaultGuardian"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/utils.py",
        "size": 1593,
        "lines": 54,
        "functions": [
          "validate_content_ethics",
          "check_compliance_status",
          "generate_compliance_report",
          "anonymize_metadata"
        ],
        "classes": [
          "EthicsUtils"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/glyph_ethics_validator.py",
        "size": 42204,
        "lines": 1020,
        "functions": [
          "is_applicable",
          "is_approved",
          "is_safe",
          "__init__",
          "validate_glyph_creation",
          "validate_glyph_mutation",
          "validate_glyph_fusion",
          "validate_glyph_decay",
          "_initialize_ethical_constraints",
          "_initialize_content_filters",
          "_validate_content_safety",
          "_validate_emotional_boundaries",
          "_validate_symbolic_integrity",
          "_validate_privacy_compliance",
          "_validate_mutation_authorization",
          "_validate_mutation_impact",
          "_validate_mutation_continuity",
          "_validate_fusion_compatibility",
          "_validate_fusion_consent",
          "_validate_fusion_result_integrity",
          "_validate_memory_preservation",
          "_validate_decay_dependencies",
          "_validate_data_retention",
          "_calculate_ethical_score",
          "_calculate_safety_score",
          "_calculate_decay_ethical_score",
          "_calculate_decay_safety_score",
          "_determine_validation_result",
          "_determine_decay_validation_result",
          "_generate_creation_recommendations",
          "_generate_mutation_recommendations",
          "_generate_fusion_recommendations",
          "_generate_decay_recommendations",
          "_glyphs_have_conflicting_ethics",
          "get_validation_statistics"
        ],
        "classes": [
          "EthicalViolationType",
          "ValidationResult",
          "EthicalConstraint",
          "ValidationReport",
          "GlyphEthicsValidator"
        ],
        "security_score": 10
      },
      {
        "path": "ethics/governance_checker.py",
        "size": 3872,
        "lines": 102,
        "functions": [
          "is_fine_tunable",
          "validate_symbolic_integrity",
          "log_governance_trace"
        ],
        "classes": [],
        "security_score": 6
      },
      {
        "path": "ethics/hitlo_bridge.py",
        "size": 22525,
        "lines": 546,
        "functions": [
          "create_ethics_hitlo_bridge",
          "should_escalate",
          "__init__",
          "_setup_default_rules",
          "add_escalation_rule",
          "should_escalate_evaluation",
          "_create_review_context",
          "_categorize_risk_level",
          "_generate_review_questions",
          "_update_metrics",
          "get_metrics",
          "configure_human_oversight",
          "configure_oversight"
        ],
        "classes": [
          "EthicsEscalationRule",
          "EthicsHITLOBridge"
        ],
        "security_score": 5
      },
      {
        "path": "ethics/hitlo_bridge_simple.py",
        "size": 1364,
        "lines": 42,
        "functions": [
          "__init__",
          "configure_human_oversight",
          "configure_oversight"
        ],
        "classes": [
          "HITLOBridge"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/meg_guard.py",
        "size": 10216,
        "lines": 282,
        "functions": [
          "demo_meg_usage",
          "__init__",
          "_check_rate_limit",
          "_ethical_check",
          "guard",
          "get_stats",
          "temporary_disable_ethics",
          "critical_operation",
          "decorator",
          "sync_wrapper"
        ],
        "classes": [
          "MEGConfig",
          "MEG"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/ethics.py",
        "size": 2911,
        "lines": 66,
        "functions": [
          "main"
        ],
        "classes": [],
        "security_score": 2
      },
      {
        "path": "ethics/ethical_reasoning_system.py",
        "size": 87197,
        "lines": 2201,
        "functions": [
          "__init__",
          "_generate_universalization_reasoning",
          "_generate_humanity_reasoning",
          "_generate_kingdom_reasoning",
          "_identify_relevant_duties",
          "_find_duty_conflicts",
          "_resolve_duty_conflicts",
          "_calculate_deontological_confidence",
          "__init__",
          "_check_preference_satisfaction",
          "_affects_capability",
          "_priority_weighted_aggregation",
          "_calculate_consequentialist_confidence",
          "_generate_utilitarian_justification",
          "__init__",
          "_identify_relevant_values",
          "_extract_values_from_text",
          "_calculate_value_drift_rate",
          "_identify_misalignment_risks",
          "_suggest_alignment_interventions",
          "__init__",
          "_initialize_default_constraints",
          "_initialize_drift_detector",
          "_create_constraint_violation_judgment",
          "_estimate_impact_magnitude",
          "_estimate_impact_valence",
          "_identify_specific_impacts",
          "_identify_mitigation_needs",
          "_identify_uncertainty_factors",
          "_calculate_overall_confidence",
          "_extract_principle_weights",
          "_calculate_framework_consensus",
          "_identify_potential_harms",
          "_generate_mitigation_strategies"
        ],
        "classes": [
          "EthicalFramework",
          "MoralPrinciple",
          "StakeholderType",
          "EthicalDilemmaType",
          "MoralJudgment",
          "ValueAlignment",
          "EthicalConstraint",
          "DeontologicalReasoner",
          "ConsequentialistReasoner",
          "ValueAlignmentSystem",
          "EthicalReasoningSystem"
        ],
        "security_score": 2
      },
      {
        "path": "ethics/governance_validator.py",
        "size": 7817,
        "lines": 213,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/decision_framework.py",
        "size": 7789,
        "lines": 213,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/meg_openai_guard.py",
        "size": 9813,
        "lines": 314,
        "functions": [
          "meg_chat_completion",
          "meg_chat_completion_critical",
          "meg_chat_completion_extended",
          "meg_chat_completion_long",
          "meg_generate_text",
          "meg_complete_with_system",
          "patch_openai_with_meg",
          "unpatch_openai",
          "_generate",
          "_complete",
          "create"
        ],
        "classes": [
          "MEGChatCompletion"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/meg_bridge.py",
        "size": 11891,
        "lines": 293,
        "functions": [
          "create_meg_bridge",
          "__init__",
          "ethics_decision_to_meg_decision",
          "meg_evaluation_to_ethics_evaluation",
          "get_cultural_context_info",
          "get_meg_status",
          "add_meg_callback",
          "get_human_review_queue"
        ],
        "classes": [
          "MEGPolicyBridge"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/governance_model.py",
        "size": 7761,
        "lines": 213,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/ethical_evaluator.py",
        "size": 1172,
        "lines": 38,
        "functions": [
          "evaluate",
          "collapse",
          "store",
          "trace"
        ],
        "classes": [
          "EthicalEvaluator",
          "CollapseEngine",
          "Memoria"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/dao_community.py",
        "size": 24031,
        "lines": 595,
        "functions": [],
        "classes": [],
        "security_score": 6
      },
      {
        "path": "ethics/compliance_validator.py",
        "size": 8873,
        "lines": 257,
        "functions": [
          "create_governance_component",
          "__init__",
          "get_status",
          "validate"
        ],
        "classes": [
          "ComplianceValidator"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/bases.py",
        "size": 2591,
        "lines": 83,
        "functions": [
          "__init__",
          "add_compliance_rule",
          "check_compliance",
          "_check_rule",
          "__init__",
          "add_rule",
          "validate_action",
          "_validate_rule",
          "__init__",
          "to_dict"
        ],
        "classes": [
          "ComplianceEngine",
          "ComplianceFramework",
          "ComplianceViolation"
        ],
        "security_score": 2
      },
      {
        "path": "ethics/ethics_integration.py",
        "size": 14416,
        "lines": 390,
        "functions": [
          "get_ethics_integration",
          "__init__",
          "_establish_connections",
          "_determine_decision_type",
          "_record_decision"
        ],
        "classes": [
          "EthicalDecisionType",
          "EthicsIntegration"
        ],
        "security_score": 5
      },
      {
        "path": "ethics/stabilization/__init__.py",
        "size": 29,
        "lines": 1,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/stabilization/tuner.py",
        "size": 31481,
        "lines": 826,
        "functions": [
          "main",
          "add_datapoint",
          "get_trend_slope",
          "is_unstable",
          "get_stabilizer",
          "get_applicable_stabilizers",
          "__init__",
          "_load_config",
          "monitor_entanglement",
          "_generate_synthetic_log_data",
          "_update_trends",
          "detect_instability",
          "_in_cooldown_period",
          "select_stabilizers",
          "apply_symbolic_correction",
          "_inject_stabilizer",
          "_calculate_severity",
          "_generate_justification",
          "emit_tuning_log",
          "get_stabilization_status"
        ],
        "classes": [
          "StabilizationAction",
          "EntanglementTrend",
          "SymbolicStabilizer",
          "AdaptiveEntanglementStabilizer"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/tools/quantum_mesh_visualizer.py",
        "size": 41086,
        "lines": 1103,
        "functions": [
          "main",
          "__init__",
          "_setup_color_schemes",
          "load_entanglement_data",
          "_load_live_data",
          "_load_from_logs",
          "_generate_synthetic_data",
          "generate_entanglement_heatmap",
          "plot_phase_synchronization",
          "list_active_conflict_pairs",
          "generate_interactive_dashboard",
          "_generate_static_dashboard",
          "export_visual_summary",
          "_export_markdown_report",
          "_export_html_report",
          "_export_json_snapshot",
          "_create_html_template",
          "_format_conflicts_html",
          "_format_entanglements_html"
        ],
        "classes": [
          "QuantumMeshVisualizer"
        ],
        "security_score": 1
      },
      {
        "path": "ethics/tools/__init__.py",
        "size": 21,
        "lines": 1,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/tools/lambda_auditor.py",
        "size": 43975,
        "lines": 1046,
        "functions": [],
        "classes": [],
        "security_score": 5
      },
      {
        "path": "ethics/governor/__init__.py",
        "size": 1056,
        "lines": 44,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/governor/lambda_governor.py",
        "size": 38453,
        "lines": 1006,
        "functions": [
          "create_escalation_signal",
          "to_dict",
          "calculate_urgency_score",
          "to_dict",
          "add_log_entry",
          "__init__",
          "register_mesh_router",
          "register_dream_coordinator",
          "register_memory_manager",
          "register_subsystem_callback",
          "get_governor_status",
          "_calculate_decision_confidence",
          "_generate_intervention_tags",
          "_generate_reasoning",
          "_determine_quarantine_scope",
          "_create_rollback_plan",
          "_update_stats",
          "_is_recent"
        ],
        "classes": [
          "ActionDecision",
          "EscalationSource",
          "EscalationPriority",
          "EscalationSignal",
          "ArbitrationResponse",
          "InterventionExecution",
          "LambdaGovernor"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/governor/dao_controller.py",
        "size": 7596,
        "lines": 204,
        "functions": [
          "__init__",
          "_initialize_council",
          "create_proposal",
          "get_proposal",
          "vote_on_proposal",
          "_check_proposal_status",
          "_execute_proposal",
          "_execute_system_update",
          "_execute_ethical_decision",
          "_execute_resource_allocation",
          "_simulate_voting"
        ],
        "classes": [
          "DAOGovernanceNode"
        ],
        "security_score": 1
      },
      {
        "path": "ethics/core/shared_ethics_engine.py",
        "size": 20273,
        "lines": 536,
        "functions": [
          "get_shared_ethics_engine",
          "__init__",
          "_initialize_constraints",
          "_initialize_principle_weights",
          "add_constraint",
          "_requires_consent",
          "_check_constraint_violation",
          "_calculate_decision",
          "_generate_recommendations",
          "_summarize_context",
          "get_ethics_report"
        ],
        "classes": [
          "EthicalPrinciple",
          "EthicalSeverity",
          "DecisionType",
          "EthicalConstraint",
          "EthicalDecision",
          "SharedEthicsEngine"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/core/__init__.py",
        "size": 499,
        "lines": 27,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/fallback/__init__.py",
        "size": 124,
        "lines": 6,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/fallback/ethics_layer.py",
        "size": 526,
        "lines": 22,
        "functions": [
          "__init__",
          "is_allowed"
        ],
        "classes": [
          "FallbackEthicsLayer"
        ],
        "security_score": 0
      },
      {
        "path": "ethics/security/main_node_security_engine.py",
        "size": 14543,
        "lines": 404,
        "functions": [
          "__init__",
          "init_components",
          "register_event_handlers",
          "_calculate_duration",
          "_get_memory_usage",
          "_save_system_state"
        ],
        "classes": [
          "MainNodeSecurityEngine"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/security/emergency_override.py",
        "size": 2422,
        "lines": 59,
        "functions": [
          "check_safety_flags",
          "shutdown_systems",
          "log_incident"
        ],
        "classes": [],
        "security_score": 5
      },
      {
        "path": "ethics/security/security_engine.py",
        "size": 1316,
        "lines": 43,
        "functions": [
          "__init__",
          "validate_request",
          "detect_threats",
          "sanitize_data"
        ],
        "classes": [
          "SecurityEngine"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/security/__init__.py",
        "size": 484,
        "lines": 22,
        "functions": [],
        "classes": [],
        "security_score": 2
      },
      {
        "path": "ethics/security/flagship_security_engine.py",
        "size": 9005,
        "lines": 240,
        "functions": [
          "__init__"
        ],
        "classes": [
          "LukhasFlagshipSecurityEngine"
        ],
        "security_score": 2
      },
      {
        "path": "ethics/security/secure_utils.py",
        "size": 8550,
        "lines": 282,
        "functions": [
          "safe_eval",
          "_is_safe_ast",
          "safe_subprocess_run",
          "_validate_command",
          "sanitize_input",
          "secure_file_path",
          "get_env_var"
        ],
        "classes": [
          "SecurityError"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/security/privacy.py",
        "size": 223,
        "lines": 10,
        "functions": [
          "__init__"
        ],
        "classes": [
          "PrivacyManager"
        ],
        "security_score": 3
      },
      {
        "path": "ethics/training/alignment_overseer.py",
        "size": 657,
        "lines": 22,
        "functions": [
          "train_overseer_from_scenarios"
        ],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/training/__init__.py",
        "size": 32,
        "lines": 1,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/utils/__init__.py",
        "size": 29,
        "lines": 1,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/utils/tag_misinterpretation_sim.py",
        "size": 1185,
        "lines": 42,
        "functions": [
          "simulate_misinterpretation_scenarios"
        ],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/compliance/__init__.py",
        "size": 191,
        "lines": 8,
        "functions": [],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "ethics/compliance/engine.py",
        "size": 42436,
        "lines": 736,
        "functions": [
          "__init__",
          "evaluate_action",
          "_extract_action_type",
          "_extract_content",
          "_evaluate_against_framework",
          "_evaluate_utilitarian",
          "_evaluate_deontological",
          "_evaluate_virtue_ethics",
          "_evaluate_justice",
          "_evaluate_care_ethics",
          "_evaluate_against_principle",
          "_evaluate_non_maleficence",
          "_evaluate_beneficence",
          "_evaluate_autonomy",
          "_evaluate_justice_principle",
          "_evaluate_transparency",
          "_evaluate_privacy",
          "suggest_alternatives",
          "increase_scrutiny_level",
          "reset_scrutiny_level",
          "incorporate_feedback",
          "get_metrics",
          "_add_to_history",
          "__init__",
          "_ensure_log_dir",
          "_build_default_legal_knowledge_graph",
          "_build_default_sensitive_vocab",
          "check_access",
          "log_violation",
          "check_cultural_context",
          "__init__",
          "_ensure_log_dir",
          "evaluate_action_ethics",
          "evaluate_action",
          "suggest_ethical_alternatives",
          "get_core_ethics_metrics",
          "incorporate_ethics_feedback",
          "anonymize_metadata",
          "should_retain_data",
          "check_voice_data_compliance",
          "validate_content_against_harmful_patterns",
          "generate_compliance_report",
          "_generate_anonymous_id",
          "check_data_access_permission",
          "check_cultural_appropriateness",
          "perform_ethics_drift_detection",
          "_log_ethics_drift_event",
          "get_overall_compliance_status",
          "_get_last_drift_log_summary",
          "get_score"
        ],
        "classes": [
          "_CorePrivateEthicsEngine",
          "_LucasPrivateEthicsGuard",
          "AdvancedComplianceEthicsEngine"
        ],
        "security_score": 6
      },
      {
        "path": "ethics/sentinel/ethical_drift_sentinel.py",
        "size": 30983,
        "lines": 819,
        "functions": [
          "phase_harmonics_score",
          "to_dict",
          "to_dict",
          "calculate_risk_score",
          "__init__",
          "_detect_violations",
          "_create_violation",
          "_log_violation",
          "_log_escalation",
          "_check_cascade_conditions",
          "_is_recent",
          "_determine_severity",
          "_severity_rank",
          "_initialize_ethical_state",
          "_update_ethical_state",
          "get_sentinel_status",
          "_calculate_system_risk",
          "register_symbol",
          "unregister_symbol"
        ],
        "classes": [
          "EscalationTier",
          "ViolationType",
          "EthicalViolation",
          "InterventionAction",
          "EthicalState",
          "EthicalDriftSentinel"
        ],
        "security_score": 2
      },
      {
        "path": "ethics/sentinel/ethical_sentinel_dashboard.py",
        "size": 15896,
        "lines": 497,
        "functions": [
          "initialize_sentinel",
          "create_risk_gauge",
          "create_violation_timeline",
          "create_symbol_health_charts",
          "format_violation"
        ],
        "classes": [],
        "security_score": 2
      },
      {
        "path": "ethics/safety/entropy_tuning.py",
        "size": 1218,
        "lines": 46,
        "functions": [
          "final_entropy_tune",
          "recheck_entropy"
        ],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "ethics/safety/compliance_hooks.py",
        "size": 4098,
        "lines": 111,
        "functions": [
          "compliance_drift_detect",
          "log_compliance_event"
        ],
        "classes": [],
        "security_score": 7
      },
      {
        "path": "ethics/safety/compliance_dashboard.py",
        "size": 2841,
        "lines": 75,
        "functions": [],
        "classes": [],
        "security_score": 4
      },
      {
        "path": "ethics/safety/__init__.py",
        "size": 29,
        "lines": 2,
        "functions": [],
        "classes": [],
        "security_score": 0
      },
      {
        "path": "ethics/safety/integration_bridge.py",
        "size": 1157,
        "lines": 37,
        "functions": [
          "__init__"
        ],
        "classes": [
          "LUKHASSafetyBridge"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/safety/compliance_digest.py",
        "size": 3368,
        "lines": 107,
        "functions": [
          "load_emergency_logs",
          "generate_digest",
          "plot_bar"
        ],
        "classes": [],
        "security_score": 4
      },
      {
        "path": "ethics/safety/compliance_dashboard_visual.py",
        "size": 4127,
        "lines": 104,
        "functions": [],
        "classes": [],
        "security_score": 5
      },
      {
        "path": "ethics/seedra/seedra_core.py",
        "size": 16782,
        "lines": 477,
        "functions": [
          "get_seedra",
          "__init__",
          "_initialize_ethical_constraints",
          "_is_consent_valid",
          "_check_consent_level",
          "_generate_consent_version",
          "_generate_session_id",
          "_calculate_data_age"
        ],
        "classes": [
          "ConsentLevel",
          "DataSensitivity",
          "SEEDRACore"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/seedra/__init__.py",
        "size": 361,
        "lines": 21,
        "functions": [],
        "classes": [],
        "security_score": 1
      },
      {
        "path": "ethics/simulations/colony_dilemma_simulation.py",
        "size": 3622,
        "lines": 96,
        "functions": [
          "_tag_difference",
          "measure_divergence"
        ],
        "classes": [
          "DivergenceReport"
        ],
        "security_score": 1
      },
      {
        "path": "ethics/simulations/__init__.py",
        "size": 2165,
        "lines": 65,
        "functions": [],
        "classes": [],
        "security_score": 2
      },
      {
        "path": "ethics/policy_engines/__init__.py",
        "size": 2501,
        "lines": 83,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/policy_engines/integration.py",
        "size": 7871,
        "lines": 241,
        "functions": [
          "get_policy_engine",
          "evaluate_with_policies",
          "to_policy_decision",
          "__init__",
          "initialize_default_policies",
          "evaluate_governance_decision",
          "add_custom_policy",
          "get_policy_metrics",
          "shutdown"
        ],
        "classes": [
          "GovernanceDecision",
          "PolicyEngineIntegration"
        ],
        "security_score": 4
      },
      {
        "path": "ethics/policy_engines/base.py",
        "size": 15806,
        "lines": 472,
        "functions": [
          "__post_init__",
          "__post_init__",
          "__init__",
          "evaluate_decision",
          "get_policy_name",
          "get_policy_version",
          "validate_symbolic_alignment",
          "assess_drift_risk",
          "assess_collapse_risk",
          "initialize",
          "shutdown",
          "get_metrics",
          "_update_metrics",
          "__init__",
          "register_policy",
          "unregister_policy",
          "evaluate_decision",
          "get_consensus_evaluation",
          "get_active_policies",
          "get_policy_metrics"
        ],
        "classes": [
          "RiskLevel",
          "Decision",
          "EthicsEvaluation",
          "PolicyValidationError",
          "EthicsPolicy",
          "PolicyRegistry"
        ],
        "security_score": 5
      },
      {
        "path": "ethics/policy_engines/examples/gpt4_policy.py",
        "size": 14441,
        "lines": 394,
        "functions": [
          "__init__",
          "get_policy_name",
          "get_policy_version",
          "initialize",
          "evaluate_decision",
          "_get_default_system_prompt",
          "_prepare_evaluation_prompt",
          "_generate_template_response",
          "_parse_gpt_response",
          "_get_cache_key",
          "shutdown"
        ],
        "classes": [
          "GPT4Config",
          "GPT4Policy"
        ],
        "security_score": 8
      },
      {
        "path": "ethics/policy_engines/examples/__init__.py",
        "size": 2349,
        "lines": 72,
        "functions": [],
        "classes": [],
        "security_score": 3
      },
      {
        "path": "ethics/policy_engines/examples/three_laws.py",
        "size": 20459,
        "lines": 509,
        "functions": [
          "__init__",
          "get_policy_name",
          "get_policy_version",
          "evaluate_decision",
          "_evaluate_first_law",
          "_evaluate_second_law",
          "_evaluate_third_law",
          "_calculate_drift_impact",
          "validate_symbolic_alignment"
        ],
        "classes": [
          "ThreeLawsPolicy"
        ],
        "security_score": 5
      }
    ],
    "functions": [
      "compliance_engine.py:__init__",
      "compliance_engine.py:anonymize_metadata",
      "compliance_engine.py:should_retain_data",
      "compliance_engine.py:check_voice_data_compliance",
      "compliance_engine.py:validate_content_against_ethical_constraints",
      "compliance_engine.py:generate_compliance_report",
      "compliance_engine.py:_generate_anonymous_id",
      "compliance_engine.py:get_compliance_status",
      "compliance_engine.py:detect_regulatory_region",
      "compliance_engine.py:update_compliance_settings",
      "compliance_engine.py:get_audit_trail",
      "compliance_engine.py:_initialize_ethical_framework",
      "compliance_engine.py:_evaluate_bias",
      "compliance_engine.py:_evaluate_transparency",
      "compliance_engine.py:_evaluate_privacy",
      "compliance_engine.py:_evaluate_harm",
      "compliance_engine.py:_evaluate_oversight",
      "compliance_engine.py:_evaluate_autonomy",
      "compliance_engine.py:_evaluate_value_alignment",
      "compliance_engine.py:_analyze_text_content",
      "compliance_engine.py:_apply_differential_privacy",
      "compliance_engine.py:_get_applicable_regulations",
      "compliance_engine.py:_apply_region_specific_rules",
      "compliance_engine.py:_map_location_string_to_region",
      "compliance_engine.py:_record_audit",
      "compliance_engine.py:check_module_compliance",
      "compliance_engine.py:add_laplace_noise",
      "service.py:assess_action",
      "service.py:check_compliance",
      "service.py:evaluate_safety",
      "service.py:__init__",
      "service.py:assess_action",
      "service.py:check_compliance",
      "service.py:evaluate_safety",
      "service.py:audit_decision",
      "service.py:_load_ethics_rules",
      "service.py:_evaluate_action_ethics",
      "service.py:_check_regulation_compliance",
      "service.py:_assess_operation_safety",
      "service.py:_get_ethics_version",
      "service.py:verify_user_access",
      "service.py:check_consent",
      "service.py:log_activity",
      "meta_ethics_governor.py:ethical_checkpoint",
      "meta_ethics_governor.py:__init__",
      "meta_ethics_governor.py:load_principles",
      "meta_ethics_governor.py:add_principle",
      "meta_ethics_governor.py:__init__",
      "meta_ethics_governor.py:_load_default_principles",
      "meta_ethics_governor.py:_check_principle_conditions",
      "meta_ethics_governor.py:_check_violation",
      "meta_ethics_governor.py:load_principles",
      "meta_ethics_governor.py:__init__",
      "meta_ethics_governor.py:_load_default_principles",
      "meta_ethics_governor.py:load_principles",
      "meta_ethics_governor.py:__init__",
      "meta_ethics_governor.py:_initialize_default_engines",
      "meta_ethics_governor.py:_load_cultural_adapters",
      "meta_ethics_governor.py:add_ethical_engine",
      "meta_ethics_governor.py:add_event_callback",
      "meta_ethics_governor.py:get_human_review_queue",
      "meta_ethics_governor.py:resolve_human_review",
      "meta_ethics_governor.py:get_status",
      "meta_ethics_governor.py:decorator",
      "meta_ethics_governor.py:instrument_reasoning",
      "meta_ethics_governor.py:get_srd",
      "monitor.py:ethics_drift_detect",
      "monitor.py:log_ethics_event",
      "monitor.py:log_self_reflection",
      "monitor.py:self_reflection_report",
      "ethical_guardian.py:ethical_check",
      "oscillating_conscience.py:__init__",
      "oscillating_conscience.py:update",
      "compliance.py:__init__",
      "compliance.py:get_plugin_risk_score",
      "compliance.py:get_violation_history",
      "compliance.py:get_compliance_report",
      "compliance.py:_contains_sensitive_data",
      "compliance.py:_update_plugin_risk_score",
      "intrinsic_governor.py:__init__",
      "compliance_engine20250503213400_p95.py:__init__",
      "compliance_engine20250503213400_p95.py:anonymize_metadata",
      "compliance_engine20250503213400_p95.py:should_retain_data",
      "compliance_engine20250503213400_p95.py:check_voice_data_compliance",
      "compliance_engine20250503213400_p95.py:validate_content_against_ethical_constraints",
      "compliance_engine20250503213400_p95.py:generate_compliance_report",
      "compliance_engine20250503213400_p95.py:_generate_anonymous_id",
      "compliance_engine20250503213400_p95.py:get_compliance_status",
      "compliance_simple.py:__init__",
      "compliance_simple.py:get_plugin_risk_score",
      "compliance_simple.py:get_violation_history",
      "compliance_simple.py:get_compliance_report",
      "compliance_simple.py:_contains_sensitive_data",
      "compliance_simple.py:_update_plugin_risk_score",
      "batch_guard.py:create_ethics_guard",
      "batch_guard.py:__init__",
      "batch_guard.py:validate_batch_ethics",
      "batch_guard.py:_validate_single_task_ethics",
      "batch_guard.py:_contains_sensitive_data",
      "batch_guard.py:_detect_harmful_content",
      "batch_guard.py:_has_ai_disclosure",
      "batch_guard.py:_validate_symbol_compliance",
      "batch_guard.py:_determine_required_badges",
      "batch_guard.py:generate_ethics_report",
      "tier_enforcer.py:tier_required",
      "tier_enforcer.py:collapse_kernel",
      "tier_enforcer.py:decorator",
      "tier_enforcer.py:wrapper",
      "policy_manager.py:determine_active_regulations",
      "policy_manager.py:log_active_regulations",
      "simplified_ethics_integration.py:get_ethics_integration",
      "simplified_ethics_integration.py:__init__",
      "simplified_ethics_integration.py:get_ethics_status",
      "audit_ethics_monitor.py:main",
      "ethical_drift_detector.py:load_ethics_config",
      "ethical_drift_detector.py:calculate_weighted_drift_score",
      "ethical_drift_detector.py:apply_violation_tagging",
      "ethical_drift_detector.py:_calculate_violation_severity",
      "ethical_drift_detector.py:_classify_symbolically",
      "ethical_drift_detector.py:check_escalation_requirements",
      "ethical_drift_detector.py:enrich_trace_metadata",
      "ethical_drift_detector.py:export_ethics_report",
      "ethical_drift_detector.py:detect_ethical_drift",
      "ethical_drift_detector.py:_generate_recommendation",
      "ethical_drift_detector.py:_send_real_time_alerts",
      "ethical_drift_detector.py:get_system_capabilities",
      "ethical_drift_detector.py:generate_collapse_hash",
      "ethical_drift_detector.py:crypto_trace_index",
      "__init__.py:__getattr__",
      "__init__.py:__dir__",
      "community_feedback.py:load_rules",
      "community_feedback.py:save_rules",
      "community_feedback.py:apply_proposal",
      "redteam_sim.py:parse_prompts_from_file",
      "redteam_sim.py:run_redteam_simulation",
      "redteam_sim.py:main",
      "redteam_sim.py:__hash__",
      "_spikethickness.py:__init__",
      "decision_node.py:__init__",
      "decision_node.py:_initialize_principles",
      "decision_node.py:_healthcare_principles",
      "decision_node.py:_finance_principles",
      "decision_node.py:_content_moderation_principles",
      "decision_node.py:evaluate_action",
      "decision_node.py:_evaluate_principle",
      "decision_node.py:_apply_context_adjustments",
      "decision_node.py:_select_framework",
      "decision_node.py:_generate_explanation",
      "decision_node.py:_generate_alternatives",
      "decision_node.py:_add_privacy_protections",
      "decision_node.py:_add_transparency",
      "decision_node.py:_add_user_choice",
      "decision_node.py:_add_safety_measures",
      "decision_node.py:_add_human_oversight",
      "decision_node.py:_record_decision",
      "decision_node.py:_log_audit_event",
      "decision_node.py:get_principle_weights",
      "decision_node.py:set_principle_weight",
      "decision_node.py:analyze_ethical_trends",
      "decision_node.py:evaluate_content",
      "decision_node.py:_identify_content_issues",
      "decision_node.py:process_message",
      "ethics_guard.py:__init__",
      "ethics_guard.py:_load_default_rules",
      "ethics_guard.py:check_content_safety",
      "ethics_guard.py:check_privacy_compliance",
      "ethics_guard.py:ethical_review",
      "ethics_guard.py:comprehensive_compliance_check",
      "ethics_guard.py:get_compliance_report",
      "ethics_guard.py:update_rules",
      "ethics_guard.py:_generate_recommendation",
      "ethics_guard.py:anonymize_data",
      "export_report.py:export_ethics_report",
      "export_report.py:export_comprehensive_ethics_report",
      "export_report.py:__init__",
      "export_report.py:export_multi_format",
      "export_report.py:_export_json",
      "export_report.py:_export_yaml",
      "export_report.py:_export_csv",
      "export_report.py:_export_html",
      "export_report.py:_generate_html_report",
      "export_report.py:generate_dashboard_data",
      "export_report.py:_group_violations_by_severity",
      "export_report.py:_group_violations_by_attribute",
      "export_report.py:generate_audit_trail",
      "export_report.py:generate_governance_summary",
      "export_report.py:_generate_governance_recommendations",
      "quantum_mesh_integrator.py:__post_init__",
      "quantum_mesh_integrator.py:__init__",
      "quantum_mesh_integrator.py:_load_config",
      "quantum_mesh_integrator.py:integrate_ethics_mesh",
      "quantum_mesh_integrator.py:calculate_phase_entanglement_matrix",
      "quantum_mesh_integrator.py:detect_ethics_phase_conflict",
      "quantum_mesh_integrator.py:_calculate_weighted_coherence",
      "quantum_mesh_integrator.py:_calculate_weighted_confidence",
      "quantum_mesh_integrator.py:_calculate_weighted_entropy",
      "quantum_mesh_integrator.py:_calculate_weighted_alignment",
      "quantum_mesh_integrator.py:_calculate_phase_synchronization",
      "quantum_mesh_integrator.py:_calculate_stability_index",
      "quantum_mesh_integrator.py:_calculate_drift_magnitude",
      "quantum_mesh_integrator.py:_assess_risk_level",
      "quantum_mesh_integrator.py:_get_expected_entanglement",
      "quantum_mesh_integrator.py:_assess_cascade_risk",
      "quantum_mesh_integrator.py:_identify_cascade_triggers",
      "quantum_mesh_integrator.py:_create_drift_signal",
      "quantum_mesh_integrator.py:_recommend_intervention",
      "quantum_mesh_integrator.py:get_mesh_status",
      "ethical_auditor.py:__init__",
      "ethical_auditor.py:_generate_system_prompt",
      "ethical_auditor.py:_generate_user_prompt",
      "ethical_auditor.py:_parse_audit_response",
      "ethical_auditor.py:_calculate_cost",
      "ethical_auditor.py:_generate_audit_hash",
      "ethical_auditor.py:_sign_with_lambda_id",
      "ethical_auditor.py:get_audit_summary",
      "engine.py:__init__",
      "engine.py:evaluate",
      "engine.py:interpret_score",
      "guardian.py:assess_risk",
      "utils.py:validate_content_ethics",
      "utils.py:check_compliance_status",
      "utils.py:generate_compliance_report",
      "utils.py:anonymize_metadata",
      "glyph_ethics_validator.py:is_applicable",
      "glyph_ethics_validator.py:is_approved",
      "glyph_ethics_validator.py:is_safe",
      "glyph_ethics_validator.py:__init__",
      "glyph_ethics_validator.py:validate_glyph_creation",
      "glyph_ethics_validator.py:validate_glyph_mutation",
      "glyph_ethics_validator.py:validate_glyph_fusion",
      "glyph_ethics_validator.py:validate_glyph_decay",
      "glyph_ethics_validator.py:_initialize_ethical_constraints",
      "glyph_ethics_validator.py:_initialize_content_filters",
      "glyph_ethics_validator.py:_validate_content_safety",
      "glyph_ethics_validator.py:_validate_emotional_boundaries",
      "glyph_ethics_validator.py:_validate_symbolic_integrity",
      "glyph_ethics_validator.py:_validate_privacy_compliance",
      "glyph_ethics_validator.py:_validate_mutation_authorization",
      "glyph_ethics_validator.py:_validate_mutation_impact",
      "glyph_ethics_validator.py:_validate_mutation_continuity",
      "glyph_ethics_validator.py:_validate_fusion_compatibility",
      "glyph_ethics_validator.py:_validate_fusion_consent",
      "glyph_ethics_validator.py:_validate_fusion_result_integrity",
      "glyph_ethics_validator.py:_validate_memory_preservation",
      "glyph_ethics_validator.py:_validate_decay_dependencies",
      "glyph_ethics_validator.py:_validate_data_retention",
      "glyph_ethics_validator.py:_calculate_ethical_score",
      "glyph_ethics_validator.py:_calculate_safety_score",
      "glyph_ethics_validator.py:_calculate_decay_ethical_score",
      "glyph_ethics_validator.py:_calculate_decay_safety_score",
      "glyph_ethics_validator.py:_determine_validation_result",
      "glyph_ethics_validator.py:_determine_decay_validation_result",
      "glyph_ethics_validator.py:_generate_creation_recommendations",
      "glyph_ethics_validator.py:_generate_mutation_recommendations",
      "glyph_ethics_validator.py:_generate_fusion_recommendations",
      "glyph_ethics_validator.py:_generate_decay_recommendations",
      "glyph_ethics_validator.py:_glyphs_have_conflicting_ethics",
      "glyph_ethics_validator.py:get_validation_statistics",
      "governance_checker.py:is_fine_tunable",
      "governance_checker.py:validate_symbolic_integrity",
      "governance_checker.py:log_governance_trace",
      "hitlo_bridge.py:create_ethics_hitlo_bridge",
      "hitlo_bridge.py:should_escalate",
      "hitlo_bridge.py:__init__",
      "hitlo_bridge.py:_setup_default_rules",
      "hitlo_bridge.py:add_escalation_rule",
      "hitlo_bridge.py:should_escalate_evaluation",
      "hitlo_bridge.py:_create_review_context",
      "hitlo_bridge.py:_categorize_risk_level",
      "hitlo_bridge.py:_generate_review_questions",
      "hitlo_bridge.py:_update_metrics",
      "hitlo_bridge.py:get_metrics",
      "hitlo_bridge.py:configure_human_oversight",
      "hitlo_bridge.py:configure_oversight",
      "hitlo_bridge_simple.py:__init__",
      "hitlo_bridge_simple.py:configure_human_oversight",
      "hitlo_bridge_simple.py:configure_oversight",
      "meg_guard.py:demo_meg_usage",
      "meg_guard.py:__init__",
      "meg_guard.py:_check_rate_limit",
      "meg_guard.py:_ethical_check",
      "meg_guard.py:guard",
      "meg_guard.py:get_stats",
      "meg_guard.py:temporary_disable_ethics",
      "meg_guard.py:critical_operation",
      "meg_guard.py:decorator",
      "meg_guard.py:sync_wrapper",
      "ethics.py:main",
      "ethical_reasoning_system.py:__init__",
      "ethical_reasoning_system.py:_generate_universalization_reasoning",
      "ethical_reasoning_system.py:_generate_humanity_reasoning",
      "ethical_reasoning_system.py:_generate_kingdom_reasoning",
      "ethical_reasoning_system.py:_identify_relevant_duties",
      "ethical_reasoning_system.py:_find_duty_conflicts",
      "ethical_reasoning_system.py:_resolve_duty_conflicts",
      "ethical_reasoning_system.py:_calculate_deontological_confidence",
      "ethical_reasoning_system.py:__init__",
      "ethical_reasoning_system.py:_check_preference_satisfaction",
      "ethical_reasoning_system.py:_affects_capability",
      "ethical_reasoning_system.py:_priority_weighted_aggregation",
      "ethical_reasoning_system.py:_calculate_consequentialist_confidence",
      "ethical_reasoning_system.py:_generate_utilitarian_justification",
      "ethical_reasoning_system.py:__init__",
      "ethical_reasoning_system.py:_identify_relevant_values",
      "ethical_reasoning_system.py:_extract_values_from_text",
      "ethical_reasoning_system.py:_calculate_value_drift_rate",
      "ethical_reasoning_system.py:_identify_misalignment_risks",
      "ethical_reasoning_system.py:_suggest_alignment_interventions",
      "ethical_reasoning_system.py:__init__",
      "ethical_reasoning_system.py:_initialize_default_constraints",
      "ethical_reasoning_system.py:_initialize_drift_detector",
      "ethical_reasoning_system.py:_create_constraint_violation_judgment",
      "ethical_reasoning_system.py:_estimate_impact_magnitude",
      "ethical_reasoning_system.py:_estimate_impact_valence",
      "ethical_reasoning_system.py:_identify_specific_impacts",
      "ethical_reasoning_system.py:_identify_mitigation_needs",
      "ethical_reasoning_system.py:_identify_uncertainty_factors",
      "ethical_reasoning_system.py:_calculate_overall_confidence",
      "ethical_reasoning_system.py:_extract_principle_weights",
      "ethical_reasoning_system.py:_calculate_framework_consensus",
      "ethical_reasoning_system.py:_identify_potential_harms",
      "ethical_reasoning_system.py:_generate_mitigation_strategies",
      "meg_openai_guard.py:meg_chat_completion",
      "meg_openai_guard.py:meg_chat_completion_critical",
      "meg_openai_guard.py:meg_chat_completion_extended",
      "meg_openai_guard.py:meg_chat_completion_long",
      "meg_openai_guard.py:meg_generate_text",
      "meg_openai_guard.py:meg_complete_with_system",
      "meg_openai_guard.py:patch_openai_with_meg",
      "meg_openai_guard.py:unpatch_openai",
      "meg_openai_guard.py:_generate",
      "meg_openai_guard.py:_complete",
      "meg_openai_guard.py:create",
      "meg_bridge.py:create_meg_bridge",
      "meg_bridge.py:__init__",
      "meg_bridge.py:ethics_decision_to_meg_decision",
      "meg_bridge.py:meg_evaluation_to_ethics_evaluation",
      "meg_bridge.py:get_cultural_context_info",
      "meg_bridge.py:get_meg_status",
      "meg_bridge.py:add_meg_callback",
      "meg_bridge.py:get_human_review_queue",
      "ethical_evaluator.py:evaluate",
      "ethical_evaluator.py:collapse",
      "ethical_evaluator.py:store",
      "ethical_evaluator.py:trace",
      "compliance_validator.py:create_governance_component",
      "compliance_validator.py:__init__",
      "compliance_validator.py:get_status",
      "compliance_validator.py:validate",
      "bases.py:__init__",
      "bases.py:add_compliance_rule",
      "bases.py:check_compliance",
      "bases.py:_check_rule",
      "bases.py:__init__",
      "bases.py:add_rule",
      "bases.py:validate_action",
      "bases.py:_validate_rule",
      "bases.py:__init__",
      "bases.py:to_dict",
      "ethics_integration.py:get_ethics_integration",
      "ethics_integration.py:__init__",
      "ethics_integration.py:_establish_connections",
      "ethics_integration.py:_determine_decision_type",
      "ethics_integration.py:_record_decision",
      "tuner.py:main",
      "tuner.py:add_datapoint",
      "tuner.py:get_trend_slope",
      "tuner.py:is_unstable",
      "tuner.py:get_stabilizer",
      "tuner.py:get_applicable_stabilizers",
      "tuner.py:__init__",
      "tuner.py:_load_config",
      "tuner.py:monitor_entanglement",
      "tuner.py:_generate_synthetic_log_data",
      "tuner.py:_update_trends",
      "tuner.py:detect_instability",
      "tuner.py:_in_cooldown_period",
      "tuner.py:select_stabilizers",
      "tuner.py:apply_symbolic_correction",
      "tuner.py:_inject_stabilizer",
      "tuner.py:_calculate_severity",
      "tuner.py:_generate_justification",
      "tuner.py:emit_tuning_log",
      "tuner.py:get_stabilization_status",
      "quantum_mesh_visualizer.py:main",
      "quantum_mesh_visualizer.py:__init__",
      "quantum_mesh_visualizer.py:_setup_color_schemes",
      "quantum_mesh_visualizer.py:load_entanglement_data",
      "quantum_mesh_visualizer.py:_load_live_data",
      "quantum_mesh_visualizer.py:_load_from_logs",
      "quantum_mesh_visualizer.py:_generate_synthetic_data",
      "quantum_mesh_visualizer.py:generate_entanglement_heatmap",
      "quantum_mesh_visualizer.py:plot_phase_synchronization",
      "quantum_mesh_visualizer.py:list_active_conflict_pairs",
      "quantum_mesh_visualizer.py:generate_interactive_dashboard",
      "quantum_mesh_visualizer.py:_generate_static_dashboard",
      "quantum_mesh_visualizer.py:export_visual_summary",
      "quantum_mesh_visualizer.py:_export_markdown_report",
      "quantum_mesh_visualizer.py:_export_html_report",
      "quantum_mesh_visualizer.py:_export_json_snapshot",
      "quantum_mesh_visualizer.py:_create_html_template",
      "quantum_mesh_visualizer.py:_format_conflicts_html",
      "quantum_mesh_visualizer.py:_format_entanglements_html",
      "lambda_governor.py:create_escalation_signal",
      "lambda_governor.py:to_dict",
      "lambda_governor.py:calculate_urgency_score",
      "lambda_governor.py:to_dict",
      "lambda_governor.py:add_log_entry",
      "lambda_governor.py:__init__",
      "lambda_governor.py:register_mesh_router",
      "lambda_governor.py:register_dream_coordinator",
      "lambda_governor.py:register_memory_manager",
      "lambda_governor.py:register_subsystem_callback",
      "lambda_governor.py:get_governor_status",
      "lambda_governor.py:_calculate_decision_confidence",
      "lambda_governor.py:_generate_intervention_tags",
      "lambda_governor.py:_generate_reasoning",
      "lambda_governor.py:_determine_quarantine_scope",
      "lambda_governor.py:_create_rollback_plan",
      "lambda_governor.py:_update_stats",
      "lambda_governor.py:_is_recent",
      "dao_controller.py:__init__",
      "dao_controller.py:_initialize_council",
      "dao_controller.py:create_proposal",
      "dao_controller.py:get_proposal",
      "dao_controller.py:vote_on_proposal",
      "dao_controller.py:_check_proposal_status",
      "dao_controller.py:_execute_proposal",
      "dao_controller.py:_execute_system_update",
      "dao_controller.py:_execute_ethical_decision",
      "dao_controller.py:_execute_resource_allocation",
      "dao_controller.py:_simulate_voting",
      "shared_ethics_engine.py:get_shared_ethics_engine",
      "shared_ethics_engine.py:__init__",
      "shared_ethics_engine.py:_initialize_constraints",
      "shared_ethics_engine.py:_initialize_principle_weights",
      "shared_ethics_engine.py:add_constraint",
      "shared_ethics_engine.py:_requires_consent",
      "shared_ethics_engine.py:_check_constraint_violation",
      "shared_ethics_engine.py:_calculate_decision",
      "shared_ethics_engine.py:_generate_recommendations",
      "shared_ethics_engine.py:_summarize_context",
      "shared_ethics_engine.py:get_ethics_report",
      "ethics_layer.py:__init__",
      "ethics_layer.py:is_allowed",
      "main_node_security_engine.py:__init__",
      "main_node_security_engine.py:init_components",
      "main_node_security_engine.py:register_event_handlers",
      "main_node_security_engine.py:_calculate_duration",
      "main_node_security_engine.py:_get_memory_usage",
      "main_node_security_engine.py:_save_system_state",
      "emergency_override.py:check_safety_flags",
      "emergency_override.py:shutdown_systems",
      "emergency_override.py:log_incident",
      "security_engine.py:__init__",
      "security_engine.py:validate_request",
      "security_engine.py:detect_threats",
      "security_engine.py:sanitize_data",
      "flagship_security_engine.py:__init__",
      "secure_utils.py:safe_eval",
      "secure_utils.py:_is_safe_ast",
      "secure_utils.py:safe_subprocess_run",
      "secure_utils.py:_validate_command",
      "secure_utils.py:sanitize_input",
      "secure_utils.py:secure_file_path",
      "secure_utils.py:get_env_var",
      "privacy.py:__init__",
      "alignment_overseer.py:train_overseer_from_scenarios",
      "tag_misinterpretation_sim.py:simulate_misinterpretation_scenarios",
      "engine.py:__init__",
      "engine.py:evaluate_action",
      "engine.py:_extract_action_type",
      "engine.py:_extract_content",
      "engine.py:_evaluate_against_framework",
      "engine.py:_evaluate_utilitarian",
      "engine.py:_evaluate_deontological",
      "engine.py:_evaluate_virtue_ethics",
      "engine.py:_evaluate_justice",
      "engine.py:_evaluate_care_ethics",
      "engine.py:_evaluate_against_principle",
      "engine.py:_evaluate_non_maleficence",
      "engine.py:_evaluate_beneficence",
      "engine.py:_evaluate_autonomy",
      "engine.py:_evaluate_justice_principle",
      "engine.py:_evaluate_transparency",
      "engine.py:_evaluate_privacy",
      "engine.py:suggest_alternatives",
      "engine.py:increase_scrutiny_level",
      "engine.py:reset_scrutiny_level",
      "engine.py:incorporate_feedback",
      "engine.py:get_metrics",
      "engine.py:_add_to_history",
      "engine.py:__init__",
      "engine.py:_ensure_log_dir",
      "engine.py:_build_default_legal_knowledge_graph",
      "engine.py:_build_default_sensitive_vocab",
      "engine.py:check_access",
      "engine.py:log_violation",
      "engine.py:check_cultural_context",
      "engine.py:__init__",
      "engine.py:_ensure_log_dir",
      "engine.py:evaluate_action_ethics",
      "engine.py:evaluate_action",
      "engine.py:suggest_ethical_alternatives",
      "engine.py:get_core_ethics_metrics",
      "engine.py:incorporate_ethics_feedback",
      "engine.py:anonymize_metadata",
      "engine.py:should_retain_data",
      "engine.py:check_voice_data_compliance",
      "engine.py:validate_content_against_harmful_patterns",
      "engine.py:generate_compliance_report",
      "engine.py:_generate_anonymous_id",
      "engine.py:check_data_access_permission",
      "engine.py:check_cultural_appropriateness",
      "engine.py:perform_ethics_drift_detection",
      "engine.py:_log_ethics_drift_event",
      "engine.py:get_overall_compliance_status",
      "engine.py:_get_last_drift_log_summary",
      "engine.py:get_score",
      "ethical_drift_sentinel.py:phase_harmonics_score",
      "ethical_drift_sentinel.py:to_dict",
      "ethical_drift_sentinel.py:to_dict",
      "ethical_drift_sentinel.py:calculate_risk_score",
      "ethical_drift_sentinel.py:__init__",
      "ethical_drift_sentinel.py:_detect_violations",
      "ethical_drift_sentinel.py:_create_violation",
      "ethical_drift_sentinel.py:_log_violation",
      "ethical_drift_sentinel.py:_log_escalation",
      "ethical_drift_sentinel.py:_check_cascade_conditions",
      "ethical_drift_sentinel.py:_is_recent",
      "ethical_drift_sentinel.py:_determine_severity",
      "ethical_drift_sentinel.py:_severity_rank",
      "ethical_drift_sentinel.py:_initialize_ethical_state",
      "ethical_drift_sentinel.py:_update_ethical_state",
      "ethical_drift_sentinel.py:get_sentinel_status",
      "ethical_drift_sentinel.py:_calculate_system_risk",
      "ethical_drift_sentinel.py:register_symbol",
      "ethical_drift_sentinel.py:unregister_symbol",
      "ethical_sentinel_dashboard.py:initialize_sentinel",
      "ethical_sentinel_dashboard.py:create_risk_gauge",
      "ethical_sentinel_dashboard.py:create_violation_timeline",
      "ethical_sentinel_dashboard.py:create_symbol_health_charts",
      "ethical_sentinel_dashboard.py:format_violation",
      "entropy_tuning.py:final_entropy_tune",
      "entropy_tuning.py:recheck_entropy",
      "compliance_hooks.py:compliance_drift_detect",
      "compliance_hooks.py:log_compliance_event",
      "integration_bridge.py:__init__",
      "compliance_digest.py:load_emergency_logs",
      "compliance_digest.py:generate_digest",
      "compliance_digest.py:plot_bar",
      "seedra_core.py:get_seedra",
      "seedra_core.py:__init__",
      "seedra_core.py:_initialize_ethical_constraints",
      "seedra_core.py:_is_consent_valid",
      "seedra_core.py:_check_consent_level",
      "seedra_core.py:_generate_consent_version",
      "seedra_core.py:_generate_session_id",
      "seedra_core.py:_calculate_data_age",
      "colony_dilemma_simulation.py:_tag_difference",
      "colony_dilemma_simulation.py:measure_divergence",
      "integration.py:get_policy_engine",
      "integration.py:evaluate_with_policies",
      "integration.py:to_policy_decision",
      "integration.py:__init__",
      "integration.py:initialize_default_policies",
      "integration.py:evaluate_governance_decision",
      "integration.py:add_custom_policy",
      "integration.py:get_policy_metrics",
      "integration.py:shutdown",
      "base.py:__post_init__",
      "base.py:__post_init__",
      "base.py:__init__",
      "base.py:evaluate_decision",
      "base.py:get_policy_name",
      "base.py:get_policy_version",
      "base.py:validate_symbolic_alignment",
      "base.py:assess_drift_risk",
      "base.py:assess_collapse_risk",
      "base.py:initialize",
      "base.py:shutdown",
      "base.py:get_metrics",
      "base.py:_update_metrics",
      "base.py:__init__",
      "base.py:register_policy",
      "base.py:unregister_policy",
      "base.py:evaluate_decision",
      "base.py:get_consensus_evaluation",
      "base.py:get_active_policies",
      "base.py:get_policy_metrics",
      "gpt4_policy.py:__init__",
      "gpt4_policy.py:get_policy_name",
      "gpt4_policy.py:get_policy_version",
      "gpt4_policy.py:initialize",
      "gpt4_policy.py:evaluate_decision",
      "gpt4_policy.py:_get_default_system_prompt",
      "gpt4_policy.py:_prepare_evaluation_prompt",
      "gpt4_policy.py:_generate_template_response",
      "gpt4_policy.py:_parse_gpt_response",
      "gpt4_policy.py:_get_cache_key",
      "gpt4_policy.py:shutdown",
      "three_laws.py:__init__",
      "three_laws.py:get_policy_name",
      "three_laws.py:get_policy_version",
      "three_laws.py:evaluate_decision",
      "three_laws.py:_evaluate_first_law",
      "three_laws.py:_evaluate_second_law",
      "three_laws.py:_evaluate_third_law",
      "three_laws.py:_calculate_drift_impact",
      "three_laws.py:validate_symbolic_alignment"
    ],
    "classes": [
      "compliance_engine.py:ComplianceEngine",
      "service.py:EthicsService",
      "service.py:IdentityClient",
      "meta_ethics_governor.py:EthicalFramework",
      "meta_ethics_governor.py:EthicalVerdict",
      "meta_ethics_governor.py:Severity",
      "meta_ethics_governor.py:CulturalContext",
      "meta_ethics_governor.py:EthicalPrinciple",
      "meta_ethics_governor.py:EthicalDecision",
      "meta_ethics_governor.py:EthicalEvaluation",
      "meta_ethics_governor.py:EthicalFrameworkEngine",
      "meta_ethics_governor.py:DeontologicalEngine",
      "meta_ethics_governor.py:ConsequentialistEngine",
      "meta_ethics_governor.py:MetaEthicsGovernor",
      "oscillating_conscience.py:OscillatingConscience",
      "compliance.py:EthicsViolationType",
      "compliance.py:ComplianceFramework",
      "compliance.py:ComplianceViolation",
      "compliance.py:EthicsValidationResult",
      "compliance.py:EthicsComplianceEngine",
      "intrinsic_governor.py:IntrinsicEthicalGovernor",
      "compliance_engine20250503213400_p95.py:Complianceengine",
      "compliance_simple.py:EthicsViolationType",
      "compliance_simple.py:ComplianceFramework",
      "compliance_simple.py:ComplianceViolation",
      "compliance_simple.py:EthicsValidationResult",
      "compliance_simple.py:EthicsComplianceEngine",
      "batch_guard.py:EthicsLevel",
      "batch_guard.py:ComplianceStatus",
      "batch_guard.py:EthicsResult",
      "batch_guard.py:EthicsBatchGuard",
      "simplified_ethics_integration.py:SimplifiedEthicsIntegration",
      "redteam_sim.py:HashableDict",
      "_spikethickness.py:SpikethicknessValidator",
      "decision_node.py:EthicsNode",
      "ethics_guard.py:LegalComplianceAssistant",
      "export_report.py:EthicsReportExporter",
      "quantum_mesh_integrator.py:EthicsRiskLevel",
      "quantum_mesh_integrator.py:EthicsSignalType",
      "quantum_mesh_integrator.py:EthicalState",
      "quantum_mesh_integrator.py:EthicsSignal",
      "quantum_mesh_integrator.py:PhaseEntanglement",
      "quantum_mesh_integrator.py:QuantumEthicsMeshIntegrator",
      "ethical_auditor.py:AuditContext",
      "ethical_auditor.py:AuditResult",
      "ethical_auditor.py:EliteEthicalAuditor",
      "engine.py:EthicsEngine",
      "guardian.py:DefaultGuardian",
      "utils.py:EthicsUtils",
      "glyph_ethics_validator.py:EthicalViolationType",
      "glyph_ethics_validator.py:ValidationResult",
      "glyph_ethics_validator.py:EthicalConstraint",
      "glyph_ethics_validator.py:ValidationReport",
      "glyph_ethics_validator.py:GlyphEthicsValidator",
      "hitlo_bridge.py:EthicsEscalationRule",
      "hitlo_bridge.py:EthicsHITLOBridge",
      "hitlo_bridge_simple.py:HITLOBridge",
      "meg_guard.py:MEGConfig",
      "meg_guard.py:MEG",
      "ethical_reasoning_system.py:EthicalFramework",
      "ethical_reasoning_system.py:MoralPrinciple",
      "ethical_reasoning_system.py:StakeholderType",
      "ethical_reasoning_system.py:EthicalDilemmaType",
      "ethical_reasoning_system.py:MoralJudgment",
      "ethical_reasoning_system.py:ValueAlignment",
      "ethical_reasoning_system.py:EthicalConstraint",
      "ethical_reasoning_system.py:DeontologicalReasoner",
      "ethical_reasoning_system.py:ConsequentialistReasoner",
      "ethical_reasoning_system.py:ValueAlignmentSystem",
      "ethical_reasoning_system.py:EthicalReasoningSystem",
      "meg_openai_guard.py:MEGChatCompletion",
      "meg_bridge.py:MEGPolicyBridge",
      "ethical_evaluator.py:EthicalEvaluator",
      "ethical_evaluator.py:CollapseEngine",
      "ethical_evaluator.py:Memoria",
      "compliance_validator.py:ComplianceValidator",
      "bases.py:ComplianceEngine",
      "bases.py:ComplianceFramework",
      "bases.py:ComplianceViolation",
      "ethics_integration.py:EthicalDecisionType",
      "ethics_integration.py:EthicsIntegration",
      "tuner.py:StabilizationAction",
      "tuner.py:EntanglementTrend",
      "tuner.py:SymbolicStabilizer",
      "tuner.py:AdaptiveEntanglementStabilizer",
      "quantum_mesh_visualizer.py:QuantumMeshVisualizer",
      "lambda_governor.py:ActionDecision",
      "lambda_governor.py:EscalationSource",
      "lambda_governor.py:EscalationPriority",
      "lambda_governor.py:EscalationSignal",
      "lambda_governor.py:ArbitrationResponse",
      "lambda_governor.py:InterventionExecution",
      "lambda_governor.py:LambdaGovernor",
      "dao_controller.py:DAOGovernanceNode",
      "shared_ethics_engine.py:EthicalPrinciple",
      "shared_ethics_engine.py:EthicalSeverity",
      "shared_ethics_engine.py:DecisionType",
      "shared_ethics_engine.py:EthicalConstraint",
      "shared_ethics_engine.py:EthicalDecision",
      "shared_ethics_engine.py:SharedEthicsEngine",
      "ethics_layer.py:FallbackEthicsLayer",
      "main_node_security_engine.py:MainNodeSecurityEngine",
      "security_engine.py:SecurityEngine",
      "flagship_security_engine.py:LukhasFlagshipSecurityEngine",
      "secure_utils.py:SecurityError",
      "privacy.py:PrivacyManager",
      "engine.py:_CorePrivateEthicsEngine",
      "engine.py:_LucasPrivateEthicsGuard",
      "engine.py:AdvancedComplianceEthicsEngine",
      "ethical_drift_sentinel.py:EscalationTier",
      "ethical_drift_sentinel.py:ViolationType",
      "ethical_drift_sentinel.py:EthicalViolation",
      "ethical_drift_sentinel.py:InterventionAction",
      "ethical_drift_sentinel.py:EthicalState",
      "ethical_drift_sentinel.py:EthicalDriftSentinel",
      "integration_bridge.py:LUKHASSafetyBridge",
      "seedra_core.py:ConsentLevel",
      "seedra_core.py:DataSensitivity",
      "seedra_core.py:SEEDRACore",
      "colony_dilemma_simulation.py:DivergenceReport",
      "integration.py:GovernanceDecision",
      "integration.py:PolicyEngineIntegration",
      "base.py:RiskLevel",
      "base.py:Decision",
      "base.py:EthicsEvaluation",
      "base.py:PolicyValidationError",
      "base.py:EthicsPolicy",
      "base.py:PolicyRegistry",
      "gpt4_policy.py:GPT4Config",
      "gpt4_policy.py:GPT4Policy",
      "three_laws.py:ThreeLawsPolicy"
    ],
    "total_lines": 26312,
    "security_keywords": 291
  },
  "gaps": [
    {
      "category": "Privacy",
      "severity": "HIGH",
      "issue": "Insufficient privacy protection mechanisms",
      "details": "Only 1 privacy files found. Need comprehensive GDPR, data anonymization, and user consent management."
    },
    {
      "category": "Security",
      "severity": "CRITICAL",
      "issue": "Inadequate security infrastructure",
      "details": "Only 3 security files found. Missing authentication, authorization, encryption, and threat detection."
    },
    {
      "category": "Compliance",
      "severity": "HIGH",
      "issue": "Insufficient compliance framework",
      "details": "Only 1 compliance files found. Need regulatory compliance, audit trails, and policy enforcement."
    }
  ],
  "recommendations": {
    "privacy": [
      "Implement comprehensive GDPR compliance module",
      "Add data anonymization and pseudonymization tools",
      "Create user consent management system",
      "Build privacy impact assessment framework",
      "Add differential privacy mechanisms"
    ],
    "security": [
      "Implement multi-factor authentication system",
      "Add role-based access control (RBAC)",
      "Create comprehensive encryption module",
      "Build threat detection and response system",
      "Add security monitoring and alerting",
      "Implement secure communication protocols",
      "Create vulnerability scanning tools",
      "Add penetration testing framework"
    ],
    "compliance": [
      "Build regulatory compliance framework (SOC2, ISO27001)",
      "Create comprehensive audit trail system",
      "Implement policy enforcement engine",
      "Add compliance reporting and monitoring",
      "Create data retention and deletion policies",
      "Build compliance dashboard and metrics",
      "Add regulatory change management system"
    ],
    "ethics": [
      "Expand bias detection and mitigation algorithms",
      "Add fairness and transparency metrics",
      "Create ethical decision-making framework",
      "Implement AI explainability tools",
      "Add human oversight and intervention mechanisms",
      "Create ethical review board integration",
      "Build value alignment verification system"
    ]
  }
}